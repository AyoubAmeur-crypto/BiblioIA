{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae6d2a91",
   "metadata": {},
   "source": [
    "<h1>Introduction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b5c5a",
   "metadata": {},
   "source": [
    "<p>Ce projet est un syst√®me de recommandation de livres intelligent bas√© sur l'apprentissage automatique (machine learning) qui utilise l'algorithme K-Means pour le clustering et une API REST Flask pour servir les recommandations. Le syst√®me est con√ßu pour analyser les pr√©f√©rences des utilisateurs et recommander des livres pertinents en fonction de leurs habitudes de lecture, de leurs √©valuations pass√©es et des caract√©ristiques des livres.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715aca12",
   "metadata": {},
   "source": [
    "<h1>Importations</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ac010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from flask import Flask, request, jsonify\n",
    "import mysql.connector\n",
    "from flask_cors import CORS\n",
    "from mysql.connector import Error\n",
    "from contextlib import contextmanager\n",
    "import traceback\n",
    "import warnings# Manipulation de donn√©es en tables (DataFrames)\n",
    "import pandas as pd\n",
    "\n",
    "# Calculs num√©riques, matrices, tableaux\n",
    "import numpy as np\n",
    "\n",
    "# Pr√©traitement : standardisation des donn√©es et encodage des labels cat√©goriels\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Algorithme de clustering non supervis√©\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Mesures d‚Äô√©valuation de clustering\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "# R√©duction de dimensionnalit√©\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualisation graphique (plots, graphiques)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cr√©ation d'une API web l√©g√®re\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# Connexion √† une base de donn√©es MySQL\n",
    "import mysql.connector\n",
    "\n",
    "# Autoriser les requ√™tes Cross-Origin (CORS) sur l‚ÄôAPI Flask\n",
    "from flask_cors import CORS\n",
    "\n",
    "# Gestion des erreurs sp√©cifiques √† MySQL\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Contexte manager pour g√©rer proprement les ressources (ex: connexions)\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Gestion et affichage des traces d‚Äôerreurs\n",
    "import traceback\n",
    "\n",
    "# Ignorer certains avertissements (warnings)\n",
    "import warnings\n",
    "\n",
    "# Manipulation des dates et heures\n",
    "from datetime import datetime\n",
    "\n",
    "# Lecture et √©criture de donn√©es au format JSON\n",
    "import json\n",
    "\n",
    "# D√©sactiver les warnings pour un affichage plus propre\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece97b5f",
   "metadata": {},
   "source": [
    "### Silhouette Score\n",
    "\n",
    "Pour un point \\( i \\) :\n",
    "\n",
    "- \\( a(i) \\) = moyenne des distances entre \\( i \\) et les autres points du m√™me cluster.\n",
    "- \\( b(i) \\) = plus petite moyenne des distances entre \\( i \\) et les autres clusters.\n",
    "\n",
    "Le score de silhouette pour le point \\( i \\) est :\n",
    "\n",
    "$$\n",
    "s(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b959b8",
   "metadata": {},
   "source": [
    "### 2. Calinski-Harabasz Score (Indice de Calinski-Harabasz)\n",
    "\n",
    "Consid√©rons un jeu de donn√©es avec \\( n \\) points et \\( k \\) clusters.\n",
    "\n",
    "- \\( S_B \\) = dispersion entre les clusters (between-cluster scatter matrix).\n",
    "- \\( S_W \\) = dispersion √† l‚Äôint√©rieur des clusters (within-cluster scatter matrix).\n",
    "\n",
    "Le score est d√©fini par :\n",
    "\n",
    "$$\n",
    "CH = \\frac{\\operatorname{trace}(S_B)}{\\operatorname{trace}(S_W)} \\times \\frac{n - k}{k - 1}\n",
    "$$\n",
    "\n",
    "Plus ce score est √©lev√©, meilleur est le clustering (clusters bien s√©par√©s et compacts).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Davies-Bouldin Score\n",
    "\n",
    "Pour chaque cluster \\( i \\), on calcule :\n",
    "\n",
    "- \\( S_i \\) = mesure de dispersion (ex. moyenne des distances des points du cluster \\( i \\) √† son centre).\n",
    "- \\( M_{ij} \\) = distance entre les centres des clusters \\( i \\) et \\( j \\).\n",
    "\n",
    "Pour chaque cluster \\( i \\), on d√©finit :\n",
    "\n",
    "$$\n",
    "R_{ij} = \\frac{S_i + S_j}{M_{ij}}\n",
    "$$\n",
    "\n",
    "Le score de Davies-Bouldin pour le cluster \\( i \\) est :\n",
    "\n",
    "$$\n",
    "R_i = \\max_{j \\neq i} R_{ij}\n",
    "$$\n",
    "\n",
    "Le score global est la moyenne sur tous les clusters :\n",
    "\n",
    "$$\n",
    "DB = \\frac{1}{k} \\sum_{i=1}^k R_i\n",
    "$$\n",
    "\n",
    "Un score DB plus faible indique un meilleur clustering (clusters bien s√©par√©s et peu dispers√©s).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11355675",
   "metadata": {},
   "source": [
    "<h1>Configuration Initiale</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e09992",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '',\n",
    "    'database': 'reco_db'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4cf6bd",
   "metadata": {},
   "source": [
    "<h1>Variables globales (initialisation)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b2347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = None\n",
    "ratings_df = None\n",
    "users_df = None\n",
    "cart_df = None\n",
    "user_features = {}\n",
    "book_features_matrix = None\n",
    "book_id_to_index = {}\n",
    "index_to_book_id = {}\n",
    "book_clusters = {}\n",
    "kmeans_model = None\n",
    "scaler = StandardScaler()\n",
    "category_encoder = LabelEncoder()\n",
    "author_encoder = LabelEncoder()\n",
    "data_quality_report = {}\n",
    "evaluation_history = []\n",
    "feature_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a86c65",
   "metadata": {},
   "source": [
    "<h1>Fonctions d'Analyse de Donn√©es</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_quality():\n",
    "    \"\"\"Analyse la qualit√© des donn√©es\"\"\"\n",
    "    print(\"üîç Analyse de la qualit√© des donn√©es...\")\n",
    "    \n",
    "    quality_report = {\n",
    "        'books': {},\n",
    "        'ratings': {},\n",
    "        'users': {},\n",
    "        'issues': []\n",
    "    }\n",
    "    \n",
    "    # Analyse des livres\n",
    "    if books_df is not None and not books_df.empty:\n",
    "        quality_report['books']['total'] = len(books_df)\n",
    "        quality_report['books']['missing_values'] = books_df.isnull().sum().to_dict()\n",
    "        quality_report['books']['duplicates'] = books_df.duplicated(subset=['title', 'author']).sum()\n",
    "        \n",
    "        # D√©tecter les probl√®mes\n",
    "        if 'price' in books_df.columns:\n",
    "            if books_df['price'].min() <= 0:\n",
    "                quality_report['issues'].append(\"Prix non valides (‚â§ 0) d√©tect√©s\")\n",
    "        if 'stock' in books_df.columns:\n",
    "            if books_df['stock'].min() < 0:\n",
    "                quality_report['issues'].append(\"Stocks n√©gatifs d√©tect√©s\")\n",
    "    \n",
    "    # Analyse des √©valuations\n",
    "    if ratings_df is not None and not ratings_df.empty:\n",
    "        quality_report['ratings']['total'] = len(ratings_df)\n",
    "        quality_report['ratings']['missing_values'] = ratings_df.isnull().sum().to_dict()\n",
    "        quality_report['ratings']['rating_range'] = {\n",
    "            'min': ratings_df['rating'].min(),\n",
    "            'max': ratings_df['rating'].max(),\n",
    "            'mean': ratings_df['rating'].mean()\n",
    "        }\n",
    "        quality_report['ratings']['unique_users'] = ratings_df['user_id'].nunique()\n",
    "        quality_report['ratings']['unique_books'] = ratings_df['book_id'].nunique()\n",
    "        \n",
    "        # V√©rifier les √©valuations non valides\n",
    "        invalid_ratings = ratings_df[(ratings_df['rating'] < 1) | (ratings_df['rating'] > 5)]\n",
    "        if len(invalid_ratings) > 0:\n",
    "            quality_report['issues'].append(f\"{len(invalid_ratings)} √©valuations hors plage [1,5]\")\n",
    "    \n",
    "    # Analyse des utilisateurs\n",
    "    if users_df is not None and not users_df.empty:\n",
    "        quality_report['users']['total'] = len(users_df)\n",
    "        quality_report['users']['missing_values'] = users_df.isnull().sum().to_dict()\n",
    "    \n",
    "    print(f\" Analyse qualit√© termin√©e: {len(quality_report['issues'])} probl√®mes d√©tect√©s\")\n",
    "    return quality_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94768804",
   "metadata": {},
   "source": [
    "<h1>Nettoyage des donn√©es</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "251819bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_books_data(df):\n",
    "    \"\"\"Nettoyage avanc√© des donn√©es livres\"\"\"\n",
    "    print(\"üßπ Nettoyage des donn√©es livres...\")\n",
    "    \n",
    "    # Copie pour √©viter les warnings\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # 1. Gestion des valeurs manquantes\n",
    "    if 'price' in cleaned_df.columns:\n",
    "        cleaned_df['price'] = pd.to_numeric(cleaned_df['price'], errors='coerce')\n",
    "        median_price = cleaned_df['price'].median()\n",
    "        cleaned_df['price'] = cleaned_df['price'].fillna(median_price)\n",
    "        \n",
    "        # Remplacer les prix non valides\n",
    "        cleaned_df.loc[cleaned_df['price'] <= 0, 'price'] = median_price\n",
    "    \n",
    "    if 'stock' in cleaned_df.columns:\n",
    "        cleaned_df['stock'] = pd.to_numeric(cleaned_df['stock'], errors='coerce')\n",
    "        median_stock = cleaned_df['stock'].median()\n",
    "        cleaned_df['stock'] = cleaned_df['stock'].fillna(median_stock)\n",
    "        cleaned_df.loc[cleaned_df['stock'] < 0, 'stock'] = 0\n",
    "    \n",
    "    # 2. Normalisation du texte\n",
    "    if 'title' in cleaned_df.columns:\n",
    "        cleaned_df['title'] = cleaned_df['title'].str.strip().str.title()\n",
    "    \n",
    "    if 'author' in cleaned_df.columns:\n",
    "        cleaned_df['author'] = cleaned_df['author'].str.strip().str.title()\n",
    "        \n",
    "        # Encodage des auteurs\n",
    "        try:\n",
    "            cleaned_df['author_encoded'] = author_encoder.fit_transform(cleaned_df['author'])\n",
    "        except:\n",
    "            cleaned_df['author_encoded'] = 0\n",
    "    \n",
    "    # 3. Gestion des cat√©gories\n",
    "    if 'category_id' in cleaned_df.columns:\n",
    "        # Remplacer les cat√©gories manquantes\n",
    "        mode_category = cleaned_df['category_id'].mode()[0] if not cleaned_df['category_id'].mode().empty else 1\n",
    "        cleaned_df['category_id'] = cleaned_df['category_id'].fillna(mode_category)\n",
    "        \n",
    "        # Encodage\n",
    "        cleaned_df['category_encoded'] = category_encoder.fit_transform(\n",
    "            cleaned_df['category_id'].astype(str)\n",
    "        )\n",
    "    \n",
    "    # 4. Extraction de features textuelles\n",
    "    if 'title' in cleaned_df.columns:\n",
    "        cleaned_df['title_length'] = cleaned_df['title'].str.len()\n",
    "        cleaned_df['word_count'] = cleaned_df['title'].str.split().str.len()\n",
    "    \n",
    "    # 5. Features temporelles si disponible\n",
    "    if 'year' in cleaned_df.columns:\n",
    "        cleaned_df['year'] = pd.to_numeric(cleaned_df['year'], errors='coerce')\n",
    "        current_year = datetime.now().year\n",
    "        cleaned_df['age'] = current_year - cleaned_df['year'].fillna(current_year)\n",
    "        cleaned_df['age'] = cleaned_df['age'].clip(lower=0, upper=100)\n",
    "    \n",
    "    print(f\"‚úÖ Donn√©es nettoy√©es: {len(cleaned_df)} livres\")\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ebca8",
   "metadata": {},
   "source": [
    "<h1>Extraction de features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea56a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_book_features():\n",
    "    \"\"\"Extraction avanc√©e de features pour les livres\"\"\"\n",
    "    print(\"üìä Extraction de features avanc√©es...\")\n",
    "    \n",
    "    global feature_names, book_features_matrix, book_id_to_index, index_to_book_id\n",
    "    \n",
    "    features_list = []\n",
    "    book_ids = []\n",
    "    \n",
    "    for _, book in books_df.iterrows():\n",
    "        book_id = book['id']\n",
    "        book_features = {}\n",
    "        \n",
    "        # 1. Features basiques\n",
    "        book_features['price'] = float(book['price'])\n",
    "        book_features['stock'] = float(book['stock'])\n",
    "        book_features['category_encoded'] = float(book.get('category_encoded', 0))\n",
    "        book_features['author_encoded'] = float(book.get('author_encoded', 0))\n",
    "        \n",
    "        # 2. Features de popularit√©\n",
    "        if ratings_df is not None and not ratings_df.empty:\n",
    "            book_ratings = ratings_df[ratings_df['book_id'] == book_id]\n",
    "            rating_count = len(book_ratings)\n",
    "            avg_rating = book_ratings['rating'].mean() if rating_count > 0 else 3.0\n",
    "            \n",
    "            book_features['avg_rating'] = float(avg_rating)\n",
    "            book_features['rating_count'] = float(rating_count)\n",
    "            book_features['popularity'] = float(avg_rating * np.log1p(rating_count + 1))\n",
    "            \n",
    "            # Variabilit√© des notes\n",
    "            if rating_count > 1:\n",
    "                rating_std = book_ratings['rating'].std()\n",
    "                book_features['rating_std'] = float(rating_std)\n",
    "            else:\n",
    "                book_features['rating_std'] = 0.0\n",
    "        else:\n",
    "            book_features['avg_rating'] = 3.0\n",
    "            book_features['rating_count'] = 0.0\n",
    "            book_features['popularity'] = 0.0\n",
    "            book_features['rating_std'] = 0.0\n",
    "        \n",
    "        # 3. Features textuelles\n",
    "        book_features['title_length'] = float(book.get('title_length', 0))\n",
    "        book_features['word_count'] = float(book.get('word_count', 0))\n",
    "        \n",
    "        # 4. Features temporelles\n",
    "        book_features['age'] = float(book.get('age', 0))\n",
    "        \n",
    "        # 5. Feature de disponibilit√©\n",
    "        book_features['available'] = float(book['stock'] > 0) if 'stock' in book else 1.0\n",
    "        \n",
    "        # Convertir en liste dans l'ordre fixe\n",
    "        feature_names = [\n",
    "            'price', 'stock', 'category_encoded', 'author_encoded',\n",
    "            'avg_rating', 'rating_count', 'popularity', 'rating_std',\n",
    "            'title_length', 'word_count', 'age', 'available'\n",
    "        ]\n",
    "        \n",
    "        features_vector = [book_features.get(name, 0.0) for name in feature_names]\n",
    "        \n",
    "        features_list.append(features_vector)\n",
    "        book_ids.append(book_id)\n",
    "    \n",
    "    features_matrix = np.array(features_list)\n",
    "    \n",
    "    # Normalisation\n",
    "    if len(features_list) > 1:\n",
    "        features_matrix = scaler.fit_transform(features_matrix)\n",
    "    \n",
    "    # R√©duction de dimensionnalit√©\n",
    "    if features_matrix.shape[1] > 8:\n",
    "        pca = PCA(n_components=8)\n",
    "        features_matrix = pca.fit_transform(features_matrix)\n",
    "        print(f\"üìâ PCA appliqu√©: {features_matrix.shape[1]} composantes principales\")\n",
    "    \n",
    "    book_features_matrix = features_matrix\n",
    "    book_id_to_index = {book_id: idx for idx, book_id in enumerate(book_ids)}\n",
    "    index_to_book_id = {idx: book_id for idx, book_id in enumerate(book_ids)}\n",
    "    \n",
    "    print(f\"‚úÖ {len(feature_names)} features extraites pour {len(book_ids)} livres\")\n",
    "    \n",
    "    return features_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f5a3e",
   "metadata": {},
   "source": [
    "<h1>D√©tection des outliers</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c71c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(features_matrix, threshold=3):\n",
    "    \"\"\"D√©tection des outliers\"\"\"\n",
    "    print(\"üîé D√©tection des outliers...\")\n",
    "    \n",
    "    # M√©thode simple: distance √† la m√©diane\n",
    "    median = np.median(features_matrix, axis=0)\n",
    "    mad = np.median(np.abs(features_matrix - median), axis=0)\n",
    "    \n",
    "    # √âviter la division par z√©ro\n",
    "    mad[mad == 0] = 1\n",
    "    \n",
    "    # Score Z modifi√©\n",
    "    modified_z_scores = 0.6745 * (features_matrix - median) / mad\n",
    "    \n",
    "    # Identifier les outliers\n",
    "    outlier_mask = np.any(np.abs(modified_z_scores) > threshold, axis=1)\n",
    "    outlier_count = np.sum(outlier_mask)\n",
    "    \n",
    "    print(f\"‚úÖ {outlier_count} outliers d√©tect√©s ({outlier_count/len(features_matrix):.1%})\")\n",
    "    \n",
    "    return outlier_mask, outlier_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7e4fda",
   "metadata": {},
   "source": [
    "<h1> √âvaluation du clustering </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d07e5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering(features_matrix, labels, model_name=\"K-Means\"):\n",
    "    \"\"\"√âvalue la qualit√© du clustering\"\"\"\n",
    "    print(f\"üìà √âvaluation du clustering {model_name}...\")\n",
    "    \n",
    "    if len(np.unique(labels)) < 2:\n",
    "        print(\"‚ö†Ô∏è Pas assez de clusters pour l'√©valuation\")\n",
    "        return {}\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    try:\n",
    "        # 1. Silhouette Score (-1 √† 1, plus haut = mieux)\n",
    "        silhouette = silhouette_score(features_matrix, labels)\n",
    "        metrics['silhouette_score'] = float(silhouette)\n",
    "        \n",
    "        # 2. Calinski-Harabasz Index (plus haut = mieux)\n",
    "        calinski = calinski_harabasz_score(features_matrix, labels)\n",
    "        metrics['calinski_harabasz'] = float(calinski)\n",
    "        \n",
    "        # 3. Davies-Bouldin Index (plus bas = mieux)\n",
    "        davies = davies_bouldin_score(features_matrix, labels)\n",
    "        metrics['davies_bouldin'] = float(davies)\n",
    "        \n",
    "        # 4. Distribution des clusters\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        metrics['cluster_distribution'] = dict(zip(map(int, unique), map(int, counts)))\n",
    "        metrics['n_clusters'] = int(len(unique))\n",
    "        \n",
    "        # 5. Taille des clusters\n",
    "        metrics['cluster_sizes'] = {\n",
    "            'min': int(np.min(counts)),\n",
    "            'max': int(np.max(counts)),\n",
    "            'mean': float(np.mean(counts)),\n",
    "            'std': float(np.std(counts))\n",
    "        }\n",
    "        \n",
    "        # 6. Coherence intra-cluster\n",
    "        intra_cluster_distances = []\n",
    "        for cluster_id in unique:\n",
    "            cluster_points = features_matrix[labels == cluster_id]\n",
    "            if len(cluster_points) > 1:\n",
    "                centroid = np.mean(cluster_points, axis=0)\n",
    "                distances = np.linalg.norm(cluster_points - centroid, axis=1)\n",
    "                intra_cluster_distances.extend(distances)\n",
    "        \n",
    "        if intra_cluster_distances:\n",
    "            metrics['intra_cluster_distance'] = {\n",
    "                'mean': float(np.mean(intra_cluster_distances)),\n",
    "                'std': float(np.std(intra_cluster_distances))\n",
    "            }\n",
    "        \n",
    "        # Interpr√©tation\n",
    "        interpretations = []\n",
    "        \n",
    "        if silhouette > 0.7:\n",
    "            interpretations.append(\"Clusters bien s√©par√©s et denses\")\n",
    "        elif silhouette > 0.5:\n",
    "            interpretations.append(\"Clusters raisonnablement s√©par√©s\")\n",
    "        elif silhouette > 0.25:\n",
    "            interpretations.append(\"Clusters faibles, certains points mal assign√©s\")\n",
    "        else:\n",
    "            interpretations.append(\"Clusters peu d√©finis\")\n",
    "        \n",
    "        if davies < 0.5:\n",
    "            interpretations.append(\"Faible chevauchement entre clusters\")\n",
    "        elif davies < 1.0:\n",
    "            interpretations.append(\"Chevauchement mod√©r√© entre clusters\")\n",
    "        else:\n",
    "            interpretations.append(\"Fort chevauchement entre clusters\")\n",
    "        \n",
    "        metrics['interpretation'] = interpretations\n",
    "        \n",
    "        print(f\"‚úÖ √âvaluation termin√©e:\")\n",
    "        print(f\"   Silhouette: {silhouette:.3f}\")\n",
    "        print(f\"   Calinski-Harabasz: {calinski:.1f}\")\n",
    "        print(f\"   Davies-Bouldin: {davies:.3f}\")\n",
    "        print(f\"   {len(unique)} clusters, taille moyenne: {np.mean(counts):.1f}\")\n",
    "        \n",
    "        # Stocker dans l'historique\n",
    "        evaluation_history.append({\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'type': 'clustering',\n",
    "            'metrics': metrics\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur √©valuation clustering: {e}\")\n",
    "        metrics['error'] = str(e)\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a68a49",
   "metadata": {},
   "source": [
    "<h1>√âvalue la qualit√© des recommandations</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed8788d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(recommendations, user_history=None, all_books=None):\n",
    "    \"\"\"√âvalue la qualit√© des recommandations\"\"\"\n",
    "    print(\"√âvaluation des recommandations...\")\n",
    "    \n",
    "    if not recommendations:\n",
    "        return {\n",
    "            'coverage': 0,\n",
    "            'diversity': 0,\n",
    "            'novelty': 0,\n",
    "            'serendipity': 0\n",
    "        }\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. Couverture (nombre unique de livres recommand√©s / total livres)\n",
    "    if all_books is not None:\n",
    "        recommended_ids = [r['id'] for r in recommendations if isinstance(r, dict) and 'id' in r]\n",
    "        unique_recommended = set(recommended_ids)\n",
    "        metrics['coverage'] = len(unique_recommended) / len(all_books) if len(all_books) > 0 else 0\n",
    "        metrics['unique_recommended'] = len(unique_recommended)\n",
    "        metrics['total_books'] = len(all_books)\n",
    "    \n",
    "    # 2. Diversit√© (bas√©e sur les cat√©gories)\n",
    "    categories = []\n",
    "    authors = []\n",
    "    for rec in recommendations:\n",
    "        if isinstance(rec, dict):\n",
    "            if 'category_id' in rec:\n",
    "                categories.append(rec['category_id'])\n",
    "            if 'author' in rec:\n",
    "                authors.append(rec['author'])\n",
    "    \n",
    "    if categories:\n",
    "        metrics['category_diversity'] = len(set(categories)) / len(categories) if categories else 0\n",
    "    if authors:\n",
    "        metrics['author_diversity'] = len(set(authors)) / len(authors) if authors else 0\n",
    "    \n",
    "    # 3. Nouveaut√© (recommandations non vues par l'utilisateur)\n",
    "    if user_history is not None:\n",
    "        user_book_ids = set(user_history.get('evaluated_books', []))\n",
    "        new_recommendations = [r for r in recommendations \n",
    "                             if isinstance(r, dict) and r.get('id') not in user_book_ids]\n",
    "        metrics['novelty'] = len(new_recommendations) / len(recommendations) if recommendations else 0\n",
    "    \n",
    "    # 4. Score moyen\n",
    "    if recommendations and 'score' in recommendations[0]:\n",
    "        scores = [r.get('score', 0) for r in recommendations]\n",
    "        metrics['score_distribution'] = {\n",
    "            'min': float(np.min(scores)),\n",
    "            'max': float(np.max(scores)),\n",
    "            'mean': float(np.mean(scores)),\n",
    "            'std': float(np.std(scores))\n",
    "        }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f557b",
   "metadata": {},
   "source": [
    "<h1>G√©n√®re un rapport d'√©valuation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a04850d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluation_report(clustering_metrics=None, recommendation_metrics=None):\n",
    "    \"\"\"G√©n√®re un rapport d'√©valuation\"\"\"\n",
    "    print(\"üìã G√©n√©ration du rapport d'√©valuation...\")\n",
    "    \n",
    "    report = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'clustering': clustering_metrics or {},\n",
    "        'recommendations': recommendation_metrics or {},\n",
    "        'summary': {},\n",
    "        'data_quality': data_quality_report\n",
    "    }\n",
    "    \n",
    "    # R√©sum√© clustering\n",
    "    if clustering_metrics:\n",
    "        report['summary']['clustering'] = {\n",
    "            'n_clusters': clustering_metrics.get('n_clusters', 0),\n",
    "            'silhouette_score': clustering_metrics.get('silhouette_score', 0),\n",
    "            'quality': clustering_metrics.get('interpretation', ['Non √©valu√©'])[0] if clustering_metrics.get('interpretation') else 'Non √©valu√©'\n",
    "        }\n",
    "    \n",
    "    # R√©sum√© recommandations\n",
    "    if recommendation_metrics:\n",
    "        report['summary']['recommendations'] = {\n",
    "            'coverage': recommendation_metrics.get('coverage', 0),\n",
    "            'diversity': recommendation_metrics.get('category_diversity', 0),\n",
    "            'novelty': recommendation_metrics.get('novelty', 0)\n",
    "        }\n",
    "    \n",
    "    # Stocker dans l'historique\n",
    "    evaluation_history.append({\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'type': 'full_report',\n",
    "        'report': report\n",
    "    })\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfe8d9",
   "metadata": {},
   "source": [
    "<h1>Visualisation 2D des clusters</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ca75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(features_matrix, labels, save_path=\"clusters_visualization.png\"):\n",
    "    \"\"\"Visualisation 2D des clusters\"\"\"\n",
    "    try:\n",
    "        if features_matrix.shape[1] > 2:\n",
    "            # R√©duction √† 2D avec PCA\n",
    "            pca = PCA(n_components=2)\n",
    "            reduced_data = pca.fit_transform(features_matrix)\n",
    "        else:\n",
    "            reduced_data = features_matrix\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Scatter plot\n",
    "        unique_labels = np.unique(labels)\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))\n",
    "        \n",
    "        for i, label in enumerate(unique_labels):\n",
    "            cluster_points = reduced_data[labels == label]\n",
    "            plt.scatter(cluster_points[:, 0], cluster_points[:, 1],\n",
    "                      color=colors[i], label=f'Cluster {label}', alpha=0.7)\n",
    "        \n",
    "        plt.title('Visualisation des Clusters K-Means')\n",
    "        plt.xlabel('Composante principale 1')\n",
    "        plt.ylabel('Composante principale 2')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\"‚úÖ Visualisation sauvegard√©e: {save_path}\")\n",
    "        \n",
    "        plt.close()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur visualisation: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f05dc13",
   "metadata": {},
   "source": [
    "<h1>Fonctions de Base de Donn√©es</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb6402f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def get_connection():\n",
    "    \"\"\"Gestionnaire de connexion √† la base de donn√©es\"\"\"\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = mysql.connector.connect(**DB_CONFIG)\n",
    "        yield connection\n",
    "    except Error as e:\n",
    "        print(f\"‚ùå Erreur connexion MySQL: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if connection and connection.is_connected():\n",
    "            connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6266037",
   "metadata": {},
   "source": [
    "<h1>Charge les donn√©es depuis la base MySQL\"</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba24bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_db():\n",
    "    \"\"\"Charge les donn√©es depuis la base MySQL\"\"\"\n",
    "    global books_df, ratings_df, users_df, cart_df, data_quality_report\n",
    "    \n",
    "    try:\n",
    "        print(\"üìä Chargement des donn√©es depuis MySQL...\")\n",
    "        \n",
    "        with get_connection() as conn:\n",
    "            cursor = conn.cursor(dictionary=True)\n",
    "            \n",
    "            # 1. Charger les livres\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT b.*, c.name as category_name \n",
    "                FROM books b \n",
    "                LEFT JOIN categories c ON b.category_id = c.id\n",
    "            \"\"\")\n",
    "            books = cursor.fetchall()\n",
    "            books_df = pd.DataFrame(books)\n",
    "            \n",
    "            # 2. Charger les √©valuations\n",
    "            cursor.execute(\"SELECT user_id, book_id, rating FROM ratings\")\n",
    "            ratings = cursor.fetchall()\n",
    "            ratings_df = pd.DataFrame(ratings) if ratings else pd.DataFrame(columns=['user_id', 'book_id', 'rating'])\n",
    "            \n",
    "            # 3. Charger les utilisateurs\n",
    "            cursor.execute(\"SELECT id, username FROM users\")\n",
    "            users = cursor.fetchall()\n",
    "            users_df = pd.DataFrame(users) if users else pd.DataFrame(columns=['id', 'username'])\n",
    "            \n",
    "            # 4. Charger le panier\n",
    "            cursor.execute(\"SELECT user_id, book_id FROM cart\")\n",
    "            cart = cursor.fetchall()\n",
    "            cart_df = pd.DataFrame(cart) if cart else pd.DataFrame(columns=['user_id', 'book_id'])\n",
    "            \n",
    "            print(f\"‚úÖ Donn√©es brutes charg√©es: {len(books_df)} livres, {len(users_df)} utilisateurs, {len(ratings_df)} √©valuations\")\n",
    "            \n",
    "            # Analyse de la qualit√© des donn√©es\n",
    "            data_quality_report = analyze_data_quality()\n",
    "            \n",
    "            # Pr√©traitement des donn√©es\n",
    "            if len(books_df) > 0:\n",
    "                books_df = clean_books_data(books_df)\n",
    "                extract_book_features()\n",
    "                train_kmeans_model()\n",
    "                prepare_user_profiles()\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Pas de livres dans la base de donn√©es\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur chargement donn√©es: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f70c7",
   "metadata": {},
   "source": [
    "<h1>Fonctions du Mod√®le K-Means</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53b908d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kmeans_model(n_clusters=None):\n",
    "    \"\"\"Entra√Æne le mod√®le K-Means\"\"\"\n",
    "    global kmeans_model, book_clusters, book_features_matrix\n",
    "    \n",
    "    if book_features_matrix is None or len(book_features_matrix) < 2:\n",
    "        print(\"‚ùå Pas assez de donn√©es pour K-Means\")\n",
    "        return False\n",
    "    \n",
    "    print(\"ü§ñ Entra√Ænement du mod√®le K-Means...\")\n",
    "    \n",
    "    # D√©terminer le nombre optimal de clusters\n",
    "    if n_clusters is None:\n",
    "        n_books = len(book_features_matrix)\n",
    "        n_clusters = min(max(5, n_books // 5), 15)\n",
    "    \n",
    "    print(f\"üìä Utilisation de {n_clusters} clusters pour {len(book_features_matrix)} livres\")\n",
    "    \n",
    "    kmeans_model = KMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        random_state=42,\n",
    "        n_init=10,\n",
    "        max_iter=300\n",
    "    )\n",
    "    \n",
    "    # Assigner les clusters\n",
    "    clusters = kmeans_model.fit_predict(book_features_matrix)\n",
    "    \n",
    "    # Stocker les clusters par livre\n",
    "    book_clusters = {}\n",
    "    for idx, cluster_id in enumerate(clusters):\n",
    "        book_id = index_to_book_id[idx]\n",
    "        book_clusters[book_id] = int(cluster_id)\n",
    "    \n",
    "    # √âvaluer le clustering\n",
    "    clustering_metrics = evaluate_clustering(book_features_matrix, clusters)\n",
    "    \n",
    "    # Visualiser les clusters\n",
    "    visualize_clusters(book_features_matrix, clusters)\n",
    "    \n",
    "    # Afficher la distribution\n",
    "    cluster_counts = np.bincount(clusters)\n",
    "    print(f\"‚úÖ K-Means entra√Æn√© avec {n_clusters} clusters\")\n",
    "    print(f\"üìä M√©triques: Silhouette={clustering_metrics.get('silhouette_score', 0):.3f}\")\n",
    "    for i, count in enumerate(cluster_counts):\n",
    "        print(f\"   Cluster {i}: {count} livres\")\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5809091f",
   "metadata": {},
   "source": [
    "<h1>Fonctions de Profil Utilisateur</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edd460d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_user_profiles():\n",
    "    \"\"\"Pr√©pare les profils utilisateurs depuis la base de donn√©es\"\"\"\n",
    "    global user_features\n",
    "    \n",
    "    print(\"üë§ Pr√©paration des profils utilisateurs...\")\n",
    "    \n",
    "    try:\n",
    "        with get_connection() as conn:\n",
    "            cursor = conn.cursor(dictionary=True)\n",
    "            \n",
    "            # R√©cup√©rer tous les utilisateurs\n",
    "            cursor.execute(\"SELECT id FROM users\")\n",
    "            users = cursor.fetchall()\n",
    "            \n",
    "            for user in users:\n",
    "                user_id = user['id']\n",
    "                \n",
    "                # R√©cup√©rer les √©valuations de l'utilisateur\n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT r.book_id, r.rating, b.category_id, b.author, b.price\n",
    "                    FROM ratings r\n",
    "                    JOIN books b ON r.book_id = b.id\n",
    "                    WHERE r.user_id = %s\n",
    "                \"\"\", (user_id,))\n",
    "                ratings = cursor.fetchall()\n",
    "                \n",
    "                if len(ratings) >= 1:\n",
    "                    ratings_df_local = pd.DataFrame(ratings)\n",
    "                    \n",
    "                    # Calcul des pr√©f√©rences\n",
    "                    avg_rating = ratings_df_local['rating'].mean()\n",
    "                    \n",
    "                    # Cat√©gories pr√©f√©r√©es\n",
    "                    category_prefs = {}\n",
    "                    for _, row in ratings_df_local.iterrows():\n",
    "                        cat = row['category_id']\n",
    "                        rating_val = row['rating']\n",
    "                        category_prefs[cat] = category_prefs.get(cat, 0) + rating_val\n",
    "                    \n",
    "                    # Auteurs pr√©f√©r√©s\n",
    "                    author_prefs = {}\n",
    "                    for _, row in ratings_df_local.iterrows():\n",
    "                        author = row['author']\n",
    "                        rating_val = row['rating']\n",
    "                        author_prefs[author] = author_prefs.get(author, 0) + rating_val\n",
    "                    \n",
    "                    # Plage de prix pr√©f√©r√©e\n",
    "                    if not ratings_df_local.empty:\n",
    "                        avg_price = ratings_df_local['price'].mean()\n",
    "                        price_range = (max(0, avg_price * 0.5), avg_price * 1.5)\n",
    "                    else:\n",
    "                        price_range = (0, 100)\n",
    "                    \n",
    "                    user_features[user_id] = {\n",
    "                        'avg_rating': float(avg_rating),\n",
    "                        'category_prefs': dict(sorted(category_prefs.items(), key=lambda x: x[1], reverse=True)[:5]),\n",
    "                        'author_prefs': dict(sorted(author_prefs.items(), key=lambda x: x[1], reverse=True)[:10]),\n",
    "                        'preferred_price_range': price_range,\n",
    "                        'total_ratings': len(ratings),\n",
    "                        'last_updated': datetime.now().isoformat()\n",
    "                    }\n",
    "            \n",
    "            print(f\"‚úÖ Profils cr√©√©s pour {len(user_features)} utilisateurs\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur pr√©paration profils: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a75e2e",
   "metadata": {},
   "source": [
    "<h1>Recalcule le profil utilisateur</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3418fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_user_profile(user_id):\n",
    "    \"\"\"Recalcule le profil utilisateur\"\"\"\n",
    "    global user_features\n",
    "    \n",
    "    try:\n",
    "        with get_connection() as conn:\n",
    "            cursor = conn.cursor(dictionary=True)\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT r.book_id, r.rating, b.category_id, b.author, b.price\n",
    "                FROM ratings r\n",
    "                JOIN books b ON r.book_id = b.id\n",
    "                WHERE r.user_id = %s\n",
    "            \"\"\", (user_id,))\n",
    "            ratings = cursor.fetchall()\n",
    "            \n",
    "            if ratings:\n",
    "                ratings_df_local = pd.DataFrame(ratings)\n",
    "                avg_rating = ratings_df_local['rating'].mean()\n",
    "                \n",
    "                category_prefs = {}\n",
    "                author_prefs = {}\n",
    "                \n",
    "                for _, row in ratings_df_local.iterrows():\n",
    "                    cat = row['category_id']\n",
    "                    rating_val = row['rating']\n",
    "                    category_prefs[cat] = category_prefs.get(cat, 0) + rating_val\n",
    "                    \n",
    "                    author = row['author']\n",
    "                    author_prefs[author] = author_prefs.get(author, 0) + rating_val\n",
    "                \n",
    "                good_ratings = ratings_df_local[ratings_df_local['rating'] >= 4]\n",
    "                if not good_ratings.empty:\n",
    "                    avg_price = good_ratings['price'].mean()\n",
    "                    price_range = (max(0, avg_price * 0.5), avg_price * 1.5)\n",
    "                else:\n",
    "                    price_range = (0, 100)\n",
    "                \n",
    "                user_features[user_id] = {\n",
    "                    'avg_rating': float(avg_rating),\n",
    "                    'category_prefs': dict(sorted(category_prefs.items(), key=lambda x: x[1], reverse=True)[:5]),\n",
    "                    'author_prefs': dict(sorted(author_prefs.items(), key=lambda x: x[1], reverse=True)[:10]),\n",
    "                    'preferred_price_range': price_range,\n",
    "                    'total_ratings': len(ratings),\n",
    "                    'last_updated': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                print(f\"‚úÖ Profil {user_id} recalcul√©: {len(ratings)} √©valuations\")\n",
    "            else:\n",
    "                # Profil par d√©faut\n",
    "                user_features[user_id] = {\n",
    "                    'avg_rating': 3.0,\n",
    "                    'category_prefs': {},\n",
    "                    'author_prefs': {},\n",
    "                    'preferred_price_range': (0, 100),\n",
    "                    'total_ratings': 0,\n",
    "                    'last_updated': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur recalcul profil {user_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9547e391",
   "metadata": {},
   "source": [
    "<h1>R√©cup√®re le profil utilisateur</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86fbe56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_profile(user_id):\n",
    "    \"\"\"R√©cup√®re le profil utilisateur\"\"\"\n",
    "    if user_id in user_features:\n",
    "        return user_features[user_id]\n",
    "    \n",
    "    recalculate_user_profile(user_id)\n",
    "    \n",
    "    if user_id in user_features:\n",
    "        return user_features[user_id]\n",
    "    \n",
    "    return {\n",
    "        'user_id': user_id,\n",
    "        'avg_rating': 3.0,\n",
    "        'category_prefs': {},\n",
    "        'author_prefs': {},\n",
    "        'preferred_price_range': (0, 100),\n",
    "        'total_ratings': 0,\n",
    "        'last_updated': datetime.now().isoformat()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd0a43",
   "metadata": {},
   "source": [
    "<h1>Fonctions de Recommandation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20b495ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(book_id, user_id=None, n_recommendations=8):\n",
    "    \"\"\"Recommandations pour un livre avec clustering K-Means\"\"\"\n",
    "    if not kmeans_model or book_id not in book_clusters:\n",
    "        print(f\"‚ùå K-Means non entra√Æn√© ou livre {book_id} non trouv√©\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Trouver le cluster du livre\n",
    "        book_cluster = book_clusters[book_id]\n",
    "        \n",
    "        # Trouver tous les livres du m√™me cluster\n",
    "        cluster_book_ids = []\n",
    "        for bid, cid in book_clusters.items():\n",
    "            if cid == book_cluster and bid != book_id:\n",
    "                cluster_book_ids.append(bid)\n",
    "        \n",
    "        print(f\"üîç Livre {book_id} dans le cluster {book_cluster} - {len(cluster_book_ids)} livres similaires\")\n",
    "        \n",
    "        # Si pas assez de livres dans le cluster, chercher dans les clusters similaires\n",
    "        if len(cluster_book_ids) < n_recommendations:\n",
    "            print(f\"‚ö†Ô∏è Pas assez de livres dans le cluster {book_cluster}, recherche √©tendue...\")\n",
    "            \n",
    "            # Calculer la distance aux autres clusters\n",
    "            book_idx = book_id_to_index[book_id]\n",
    "            book_vector = book_features_matrix[book_idx].reshape(1, -1)\n",
    "            \n",
    "            # Trouver les distances aux centro√Ødes\n",
    "            distances = kmeans_model.transform(book_vector)[0]\n",
    "            \n",
    "            # Trier les clusters par distance\n",
    "            sorted_clusters = np.argsort(distances)\n",
    "            \n",
    "            # Prendre des livres des clusters les plus proches\n",
    "            additional_books = []\n",
    "            for cluster in sorted_clusters:\n",
    "                if cluster == book_cluster or len(additional_books) >= n_recommendations:\n",
    "                    continue\n",
    "                \n",
    "                # Trouver les livres de ce cluster\n",
    "                cluster_books = [bid for bid, cid in book_clusters.items() if cid == cluster and bid != book_id]\n",
    "                \n",
    "                # Prendre quelques livres de ce cluster\n",
    "                take_count = min(2, len(cluster_books))\n",
    "                if take_count > 0:\n",
    "                    import random\n",
    "                    selected = random.sample(cluster_books, take_count)\n",
    "                    additional_books.extend(selected)\n",
    "            \n",
    "            cluster_book_ids.extend(additional_books)\n",
    "        \n",
    "        # Limiter le nombre de livres\n",
    "        cluster_book_ids = cluster_book_ids[:n_recommendations * 3]\n",
    "        \n",
    "        recommendations = []\n",
    "        for rec_book_id in cluster_book_ids:\n",
    "            book_data = books_df[books_df['id'] == rec_book_id].iloc[0]\n",
    "            \n",
    "            # Calculer la similarit√©\n",
    "            same_cluster = book_clusters[rec_book_id] == book_cluster\n",
    "            similarity = 0.9 if same_cluster else 0.6\n",
    "            \n",
    "            personalization_score = 0\n",
    "            reason = f\"Cluster similaire ({book_cluster})\"\n",
    "            \n",
    "            if user_id and user_id in user_features:\n",
    "                profile = user_features[user_id]\n",
    "                \n",
    "                if book_data['category_id'] in profile['category_prefs']:\n",
    "                    personalization_score += profile['category_prefs'][book_data['category_id']] * 0.3\n",
    "                    reason = \"Cat√©gorie pr√©f√©r√©e dans votre cluster\"\n",
    "                \n",
    "                if book_data['author'] in profile['author_prefs']:\n",
    "                    personalization_score += profile['author_prefs'][book_data['author']] * 0.5\n",
    "                    reason = \"Auteur que vous appr√©ciez\"\n",
    "                \n",
    "                min_price, max_price = profile['preferred_price_range']\n",
    "                if min_price <= book_data['price'] <= max_price:\n",
    "                    personalization_score += 0.2\n",
    "            \n",
    "            final_score = similarity * 0.7 + personalization_score * 0.3\n",
    "            \n",
    "            recommendations.append({\n",
    "                'id': int(rec_book_id),\n",
    "                'title': str(book_data['title']),\n",
    "                'author': str(book_data['author']),\n",
    "                'category_id': int(book_data['category_id']),\n",
    "                'price': float(book_data['price']),\n",
    "                'image_url': str(book_data.get('image_url', f'https://via.placeholder.com/220x300?text={book_data[\"title\"]}')),\n",
    "                'similarity': similarity,\n",
    "                'personalization_score': personalization_score,\n",
    "                'final_score': final_score,\n",
    "                'cluster_id': int(book_clusters[rec_book_id]),\n",
    "                'reason': reason\n",
    "            })\n",
    "        \n",
    "        recommendations.sort(key=lambda x: x['final_score'], reverse=True)\n",
    "        return recommendations[:n_recommendations]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur recommandations K-Means: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98a124",
   "metadata": {},
   "source": [
    "<h1>ecommandations intelligentes bas√©es sur les pr√©f√©rences utilisateur</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac3b6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intelligent_recommendations(user_id, n_recommendations=12):\n",
    "    \"\"\"Recommandations intelligentes bas√©es sur les pr√©f√©rences utilisateur\"\"\"\n",
    "    try:\n",
    "        print(f\"üéØ D√©but recommandations intelligentes pour user {user_id}\")\n",
    "        \n",
    "        # Recharger les donn√©es √† jour\n",
    "        load_data_from_db()\n",
    "        \n",
    "        if books_df is None or books_df.empty:\n",
    "            print(\"‚ùå Pas de livres dans la base\")\n",
    "            return get_enhanced_fallback_recommendations()\n",
    "        \n",
    "        print(f\"üìö {len(books_df)} livres disponibles dans {len(set(book_clusters.values()))} clusters\")\n",
    "        \n",
    "        # Recalculer le profil\n",
    "        recalculate_user_profile(user_id)\n",
    "        \n",
    "        # R√©cup√©rer le profil\n",
    "        profile = get_user_profile(user_id)\n",
    "        \n",
    "        total_ratings = profile.get('total_ratings', 0)\n",
    "        print(f\"üìä Profil user {user_id}: {total_ratings} √©valuations\")\n",
    "        \n",
    "        # Analyser les clusters pr√©f√©r√©s de l'utilisateur\n",
    "        user_cluster_prefs = {}\n",
    "        if total_ratings > 0 and ratings_df is not None:\n",
    "            user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
    "            for _, rating_row in user_ratings.iterrows():\n",
    "                book_id = rating_row['book_id']\n",
    "                if book_id in book_clusters:\n",
    "                    cluster_id = book_clusters[book_id]\n",
    "                    rating = rating_row['rating']\n",
    "                    user_cluster_prefs[cluster_id] = user_cluster_prefs.get(cluster_id, 0) + rating\n",
    "        \n",
    "        # Trouver les clusters pr√©f√©r√©s\n",
    "        preferred_clusters = []\n",
    "        if user_cluster_prefs:\n",
    "            sorted_clusters = sorted(user_cluster_prefs.items(), key=lambda x: x[1], reverse=True)\n",
    "            preferred_clusters = [cluster_id for cluster_id, _ in sorted_clusters[:3]]\n",
    "            print(f\"üéØ Clusters pr√©f√©r√©s: {preferred_clusters}\")\n",
    "        \n",
    "        # TOUJOURS inclure des livres\n",
    "        print(\"‚ö†Ô∏è Strat√©gie: Inclure TOUS les livres (m√™me √©valu√©s) avec scores ajust√©s\")\n",
    "        \n",
    "        recommended_books = []\n",
    "        books_processed = 0\n",
    "        \n",
    "        # Livres √©valu√©s par l'utilisateur\n",
    "        user_evaluated_books = set()\n",
    "        if ratings_df is not None and not ratings_df.empty:\n",
    "            user_ratings_data = ratings_df[ratings_df['user_id'] == user_id]\n",
    "            user_evaluated_books = set(user_ratings_data['book_id'].tolist())\n",
    "        \n",
    "        print(f\"üìñ Livres √©valu√©s par user {user_id}: {len(user_evaluated_books)}\")\n",
    "        \n",
    "        # Parcourir TOUS les livres\n",
    "        for _, book in books_df.iterrows():\n",
    "            books_processed += 1\n",
    "            score = 0\n",
    "            reasons = []\n",
    "            \n",
    "            # V√©rifier si l'utilisateur a d√©j√† √©valu√© ce livre\n",
    "            is_evaluated = book['id'] in user_evaluated_books\n",
    "            \n",
    "            # R√©cup√©rer la note de l'utilisateur pour ce livre\n",
    "            user_rating = None\n",
    "            if is_evaluated and ratings_df is not None:\n",
    "                user_ratings = ratings_df[\n",
    "                    (ratings_df['user_id'] == user_id) & \n",
    "                    (ratings_df['book_id'] == book['id'])\n",
    "                ]\n",
    "                if not user_ratings.empty:\n",
    "                    user_rating = user_ratings.iloc[0]['rating']\n",
    "            \n",
    "            # Score de cluster (30%)\n",
    "            if book['id'] in book_clusters:\n",
    "                cluster_id = book_clusters[book['id']]\n",
    "                if cluster_id in preferred_clusters:\n",
    "                    cluster_score = user_cluster_prefs.get(cluster_id, 1) * 0.3\n",
    "                    score += cluster_score\n",
    "                    reasons.append(f\"Cluster pr√©f√©r√© ({cluster_id})\")\n",
    "                else:\n",
    "                    score += 0.1 * 0.3\n",
    "            \n",
    "            # Score de cat√©gorie (20%)\n",
    "            if 'category_prefs' in profile and book['category_id'] in profile['category_prefs']:\n",
    "                cat_score = profile['category_prefs'][book['category_id']]\n",
    "                if is_evaluated and user_rating:\n",
    "                    if user_rating >= 4:\n",
    "                        cat_score = cat_score * 1.2\n",
    "                        reasons.append(f\"Cat√©gorie pr√©f√©r√©e (vous avez not√© {user_rating}/5)\")\n",
    "                    elif user_rating <= 2:\n",
    "                        cat_score = cat_score * 0.3\n",
    "                    else:\n",
    "                        cat_score = cat_score * 0.7\n",
    "                else:\n",
    "                    reasons.append(\"Cat√©gorie pr√©f√©r√©e\")\n",
    "                \n",
    "                score += cat_score * 0.2\n",
    "            \n",
    "            # Score d'auteur (20%)\n",
    "            if 'author_prefs' in profile and book['author'] in profile['author_prefs']:\n",
    "                author_score = profile['author_prefs'][book['author']]\n",
    "                if is_evaluated and user_rating:\n",
    "                    if user_rating >= 4:\n",
    "                        author_score = author_score * 1.3\n",
    "                        reasons.append(f\"Auteur appr√©ci√© (vous avez not√© {user_rating}/5)\")\n",
    "                    elif user_rating <= 2:\n",
    "                        author_score = author_score * 0.2\n",
    "                    else:\n",
    "                        author_score = author_score * 0.6\n",
    "                else:\n",
    "                    reasons.append(\"Auteur appr√©ci√©\")\n",
    "                \n",
    "                score += author_score * 0.2\n",
    "            \n",
    "            # Score de prix (10%)\n",
    "            if 'preferred_price_range' in profile:\n",
    "                min_price, max_price = profile['preferred_price_range']\n",
    "                if min_price <= book['price'] <= max_price:\n",
    "                    score += 0.1\n",
    "                    reasons.append(\"Budget adapt√©\")\n",
    "            \n",
    "            # Score de popularit√© globale (10%)\n",
    "            if ratings_df is not None and not ratings_df.empty:\n",
    "                book_ratings = ratings_df[ratings_df['book_id'] == book['id']]\n",
    "                if not book_ratings.empty:\n",
    "                    avg_book_rating = book_ratings['rating'].mean()\n",
    "                    rating_count = len(book_ratings)\n",
    "                    popularity_score = avg_book_rating * np.log1p(rating_count + 1)\n",
    "                    score += popularity_score * 0.1\n",
    "                    if avg_book_rating >= 4.0:\n",
    "                        reasons.append(f\"Note: {avg_book_rating:.1f}/5\")\n",
    "            \n",
    "            # Score de nouveaut√© (10%)\n",
    "            novelty_score = 0.1 * (books_processed % 10) / 10\n",
    "            score += novelty_score\n",
    "            \n",
    "            # Score minimal pour TOUS les livres\n",
    "            base_score = 0.05\n",
    "            score += base_score\n",
    "            \n",
    "            # R√©cup√©rer les notes moyennes\n",
    "            avg_book_rating_val = 3.0\n",
    "            rating_count_val = 0\n",
    "            if ratings_df is not None and not ratings_df.empty:\n",
    "                book_ratings = ratings_df[ratings_df['book_id'] == book['id']]\n",
    "                if not book_ratings.empty:\n",
    "                    avg_book_rating_val = book_ratings['rating'].mean()\n",
    "                    rating_count_val = len(book_ratings)\n",
    "            \n",
    "            recommended_books.append({\n",
    "                'id': int(book['id']),\n",
    "                'title': str(book['title']),\n",
    "                'author': str(book['author']),\n",
    "                'score': float(score),\n",
    "                'reasons': reasons,\n",
    "                'category_id': int(book['category_id']),\n",
    "                'price': float(book['price']),\n",
    "                'image_url': book.get('image_url', f'https://via.placeholder.com/220x300?text={book[\"title\"]}'),\n",
    "                'is_evaluated': is_evaluated,\n",
    "                'user_rating': float(user_rating) if user_rating else None,\n",
    "                'avg_rating': float(avg_book_rating_val),\n",
    "                'rating_count': int(rating_count_val)\n",
    "            })\n",
    "        \n",
    "        print(f\"üìö {len(recommended_books)} livres √©valu√©s pour recommandation\")\n",
    "        \n",
    "        # Trier par score\n",
    "        recommended_books.sort(key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        # Appliquer diversit√© intelligente\n",
    "        final_recommendations = []\n",
    "        categories_used = set()\n",
    "        authors_used = set()\n",
    "        clusters_used = set()\n",
    "        \n",
    "        # M√©langer livres √©valu√©s et non √©valu√©s\n",
    "        evaluated_included = 0\n",
    "        non_evaluated_included = 0\n",
    "        \n",
    "        for book in recommended_books:\n",
    "            if len(final_recommendations) >= n_recommendations:\n",
    "                break\n",
    "            \n",
    "            # Crit√®res de diversit√©\n",
    "            category_ok = (len(categories_used) < 4 or book['category_id'] not in categories_used)\n",
    "            author_ok = (len(authors_used) < 6 or book['author'] not in authors_used)\n",
    "            \n",
    "            # V√©rifier le cluster\n",
    "            cluster_id = book_clusters.get(book['id'])\n",
    "            cluster_ok = True\n",
    "            if cluster_id is not None:\n",
    "                cluster_books = [b for b in final_recommendations if book_clusters.get(b['id']) == cluster_id]\n",
    "                if len(cluster_books) >= 3:\n",
    "                    cluster_ok = False\n",
    "            \n",
    "            if (category_ok or author_ok) and cluster_ok:\n",
    "                # G√©n√©rer une raison personnalis√©e\n",
    "                if book['is_evaluated']:\n",
    "                    if book['user_rating']:\n",
    "                        if book['user_rating'] >= 4:\n",
    "                            reason = f\"‚≠ê Vous avez ador√© ({book['user_rating']}/5) - {format_reasons(book['reasons'])}\"\n",
    "                        elif book['user_rating'] <= 2:\n",
    "                            reason = f\"‚Ü©Ô∏è Vous pourriez r√©√©valuer ({book['user_rating']}/5)\"\n",
    "                        else:\n",
    "                            reason = f\"üìñ D√©j√† lu ({book['user_rating']}/5) - {format_reasons(book['reasons'])}\"\n",
    "                    else:\n",
    "                        reason = \"üìö D√©j√† consult√© - \" + format_reasons(book['reasons'])\n",
    "                    evaluated_included += 1\n",
    "                else:\n",
    "                    if book['avg_rating'] >= 4.5 and book['rating_count'] > 5:\n",
    "                        reason = f\"üèÜ Excellent livre ({book['avg_rating']:.1f}/5) - \" + format_reasons(book['reasons'])\n",
    "                    elif book['avg_rating'] >= 4.0:\n",
    "                        reason = f\"üëç Tr√®s bien not√© ({book['avg_rating']:.1f}/5) - \" + format_reasons(book['reasons'])\n",
    "                    else:\n",
    "                        reason = \"üéØ Recommandation personnalis√©e - \" + format_reasons(book['reasons'])\n",
    "                    non_evaluated_included += 1\n",
    "                \n",
    "                final_recommendations.append({\n",
    "                    **book,\n",
    "                    'reason': reason or \"Recommand√© pour vous\"\n",
    "                })\n",
    "                \n",
    "                categories_used.add(book['category_id'])\n",
    "                authors_used.add(book['author'])\n",
    "                if cluster_id is not None:\n",
    "                    clusters_used.add(cluster_id)\n",
    "        \n",
    "        # GARANTIE: Si moins de recommandations que demand√©, prendre les meilleurs restants\n",
    "        if len(final_recommendations) < n_recommendations:\n",
    "            print(f\"‚ö†Ô∏è Seulement {len(final_recommendations)} recommandations apr√®s diversit√©, ajout des meilleurs restants\")\n",
    "            for book in recommended_books:\n",
    "                if book['id'] not in [r['id'] for r in final_recommendations]:\n",
    "                    reason = book.get('reason', 'Suggestion bas√©e sur nos collections')\n",
    "                    if not reason and book['is_evaluated'] and book['user_rating']:\n",
    "                        reason = f\"Vous avez not√© {book['user_rating']}/5\"\n",
    "                    \n",
    "                    final_recommendations.append({\n",
    "                        **book,\n",
    "                        'reason': reason or \"Suggestion personnalis√©e\"\n",
    "                    })\n",
    "                \n",
    "                if len(final_recommendations) >= n_recommendations:\n",
    "                    break\n",
    "        \n",
    "        print(f\"‚úÖ {len(final_recommendations)} recommandations FINALES pour user {user_id} \"\n",
    "              f\"({evaluated_included} d√©j√† √©valu√©s, {non_evaluated_included} nouveaux)\")\n",
    "        \n",
    "        return final_recommendations\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur recommandations intelligentes: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return get_enhanced_fallback_recommendations()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c747048",
   "metadata": {},
   "source": [
    "<h1>Fallback am√©lior√© qui retourne TOUJOURS des livres</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c9909e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enhanced_fallback_recommendations():\n",
    "    \"\"\"Fallback am√©lior√© qui retourne TOUJOURS des livres\"\"\"\n",
    "    try:\n",
    "        print(\"üîÑ Utilisation du fallback am√©lior√©\")\n",
    "        \n",
    "        if books_df is None or books_df.empty:\n",
    "            print(\"‚ùå Base de donn√©es vide dans fallback\")\n",
    "            return []\n",
    "        \n",
    "        fallback_books = []\n",
    "        \n",
    "        for idx, book in books_df.iterrows():\n",
    "            if len(fallback_books) >= 12:\n",
    "                break\n",
    "            \n",
    "            # Calculer un score basique GARANTI\n",
    "            score = 0.5 + (idx % 10) * 0.05\n",
    "            \n",
    "            # Score de popularit√©\n",
    "            if ratings_df is not None and not ratings_df.empty:\n",
    "                book_ratings = ratings_df[ratings_df['book_id'] == book['id']]\n",
    "                if not book_ratings.empty:\n",
    "                    avg_rating = book_ratings['rating'].mean()\n",
    "                    rating_count = len(book_ratings)\n",
    "                    score += avg_rating * 0.2\n",
    "                    score += np.log1p(rating_count) * 0.1\n",
    "            \n",
    "            # Score minimal\n",
    "            if score < 0.3:\n",
    "                score = 0.3\n",
    "            \n",
    "            # R√©cup√©rer la note moyenne\n",
    "            avg_rating = 3.0\n",
    "            rating_count = 0\n",
    "            if ratings_df is not None and not ratings_df.empty:\n",
    "                book_ratings = ratings_df[ratings_df['book_id'] == book['id']]\n",
    "                if not book_ratings.empty:\n",
    "                    avg_rating = book_ratings['rating'].mean()\n",
    "                    rating_count = len(book_ratings)\n",
    "            \n",
    "            fallback_books.append({\n",
    "                'id': int(book['id']),\n",
    "                'title': str(book['title']),\n",
    "                'author': str(book['author']),\n",
    "                'category_id': int(book['category_id']),\n",
    "                'price': float(book['price']),\n",
    "                'image_url': book.get('image_url', f'https://via.placeholder.com/220x300?text={book[\"title\"]}'),\n",
    "                'score': float(score),\n",
    "                'avg_rating': float(avg_rating),\n",
    "                'rating_count': int(rating_count),\n",
    "                'reason': f\"Livre populaire ({avg_rating:.1f}/5)\" if rating_count > 0 else \"D√©couverte recommand√©e\"\n",
    "            })\n",
    "        \n",
    "        # GARANTIE: Toujours retourner au moins 12 livres\n",
    "        if len(fallback_books) < 12:\n",
    "            print(f\"‚ö†Ô∏è Seulement {len(fallback_books)} livres, duplicata autoris√©\")\n",
    "            while len(fallback_books) < 12 and len(fallback_books) > 0:\n",
    "                for book in fallback_books.copy():\n",
    "                    if len(fallback_books) >= 12:\n",
    "                        break\n",
    "                    new_book = book.copy()\n",
    "                    new_book['reason'] = \"Suggestion suppl√©mentaire\"\n",
    "                    fallback_books.append(new_book)\n",
    "        \n",
    "        # Trier par score\n",
    "        fallback_books.sort(key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        print(f\"‚úÖ {len(fallback_books)} livres dans fallback\")\n",
    "        return fallback_books[:12]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur fallback: {e}\")\n",
    "        return [\n",
    "            {\n",
    "                'id': 999,\n",
    "                'title': 'Livre recommand√©',\n",
    "                'author': 'Auteur',\n",
    "                'category_id': 1,\n",
    "                'price': 19.99,\n",
    "                'image_url': 'https://via.placeholder.com/220x300?text=Livre',\n",
    "                'reason': 'Recommandation syst√®me'\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4618ff62",
   "metadata": {},
   "source": [
    "<h1>Formate les raisons pour l'affichage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10867e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reasons(reasons):\n",
    "    \"\"\"Formate les raisons pour l'affichage\"\"\"\n",
    "    if not reasons:\n",
    "        return \"Recommand√© pour vous\"\n",
    "    \n",
    "    if len(reasons) > 2:\n",
    "        return f\"{reasons[0]}, {reasons[1]}\"\n",
    "    return \", \".join(reasons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094e4aa",
   "metadata": {},
   "source": [
    "<h1>Ex√©cution et Test</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "235f6366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ D√©marrage du syst√®me de recommandation...\n",
      "üìä Chargement des donn√©es depuis MySQL...\n",
      "‚úÖ Donn√©es brutes charg√©es: 503 livres, 6 utilisateurs, 39 √©valuations\n",
      "üîç Analyse de la qualit√© des donn√©es...\n",
      "‚úÖ Analyse qualit√© termin√©e: 0 probl√®mes d√©tect√©s\n",
      "üßπ Nettoyage des donn√©es livres...\n",
      "‚úÖ Donn√©es nettoy√©es: 503 livres\n",
      "üìä Extraction de features avanc√©es...\n",
      "üìâ PCA appliqu√©: 8 composantes principales\n",
      "‚úÖ 12 features extraites pour 503 livres\n",
      "ü§ñ Entra√Ænement du mod√®le K-Means...\n",
      "üìä Utilisation de 15 clusters pour 503 livres\n",
      "üìà √âvaluation du clustering K-Means...\n",
      "‚úÖ √âvaluation termin√©e:\n",
      "   Silhouette: 0.242\n",
      "   Calinski-Harabasz: 129.1\n",
      "   Davies-Bouldin: 1.096\n",
      "   15 clusters, taille moyenne: 33.5\n",
      "‚úÖ Visualisation sauvegard√©e: clusters_visualization.png\n",
      "‚úÖ K-Means entra√Æn√© avec 15 clusters\n",
      "üìä M√©triques: Silhouette=0.242\n",
      "   Cluster 0: 72 livres\n",
      "   Cluster 1: 4 livres\n",
      "   Cluster 2: 48 livres\n",
      "   Cluster 3: 66 livres\n",
      "   Cluster 4: 2 livres\n",
      "   Cluster 5: 57 livres\n",
      "   Cluster 6: 69 livres\n",
      "   Cluster 7: 53 livres\n",
      "   Cluster 8: 3 livres\n",
      "   Cluster 9: 15 livres\n",
      "   Cluster 10: 5 livres\n",
      "   Cluster 11: 47 livres\n",
      "   Cluster 12: 8 livres\n",
      "   Cluster 13: 3 livres\n",
      "   Cluster 14: 51 livres\n",
      "üë§ Pr√©paration des profils utilisateurs...\n",
      "‚úÖ Profils cr√©√©s pour 6 utilisateurs\n",
      "\n",
      "==================================================\n",
      "√âVALUATION AUTOMATIQUE AU D√âMARRAGE\n",
      "==================================================\n",
      "üìà √âvaluation du clustering K-Means...\n",
      "‚úÖ √âvaluation termin√©e:\n",
      "   Silhouette: 0.242\n",
      "   Calinski-Harabasz: 129.1\n",
      "   Davies-Bouldin: 1.096\n",
      "   15 clusters, taille moyenne: 33.5\n",
      "\n",
      "üìä R√©sum√© clustering:\n",
      "   Score Silhouette: 0.242\n",
      "   Davies-Bouldin: 1.096\n",
      "   15 clusters\n",
      "\n",
      "üìà Qualit√© des donn√©es:\n",
      "   Livres: 503\n",
      "   √âvaluations: 39\n",
      "   Probl√®mes d√©tect√©s: 0\n",
      "\n",
      "‚úÖ Syst√®me pr√™t pour les tests!\n"
     ]
    }
   ],
   "source": [
    "print(\"üöÄ D√©marrage du syst√®me de recommandation...\")\n",
    "\n",
    "# Charger les donn√©es\n",
    "load_data_from_db()\n",
    "\n",
    "# Ex√©cuter une √©valuation automatique au d√©marrage\n",
    "if book_clusters and book_features_matrix is not None:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"√âVALUATION AUTOMATIQUE AU D√âMARRAGE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    clusters = []\n",
    "    valid_indices = []\n",
    "    for idx, book_id in index_to_book_id.items():\n",
    "        cluster_id = book_clusters.get(book_id, -1)\n",
    "        if cluster_id != -1:\n",
    "            clusters.append(cluster_id)\n",
    "            valid_indices.append(idx)\n",
    "    \n",
    "    if clusters:\n",
    "        clusters_array = np.array(clusters)\n",
    "        features_subset = book_features_matrix[valid_indices]\n",
    "        \n",
    "        if len(np.unique(clusters_array)) > 1:\n",
    "            metrics = evaluate_clustering(features_subset, clusters_array)\n",
    "            print(f\"\\nüìä R√©sum√© clustering:\")\n",
    "            print(f\"   Score Silhouette: {metrics.get('silhouette_score', 0):.3f}\")\n",
    "            print(f\"   Davies-Bouldin: {metrics.get('davies_bouldin', 0):.3f}\")\n",
    "            print(f\"   {metrics.get('n_clusters', 0)} clusters\")\n",
    "    \n",
    "    # Afficher le rapport de qualit√©\n",
    "    if data_quality_report:\n",
    "        print(f\"\\nüìà Qualit√© des donn√©es:\")\n",
    "        print(f\"   Livres: {data_quality_report.get('books', {}).get('total', 0)}\")\n",
    "        print(f\"   √âvaluations: {data_quality_report.get('ratings', {}).get('total', 0)}\")\n",
    "        if 'issues' in data_quality_report:\n",
    "            print(f\"   Probl√®mes d√©tect√©s: {len(data_quality_report['issues'])}\")\n",
    "            for issue in data_quality_report['issues']:\n",
    "                print(f\"     - {issue}\")\n",
    "\n",
    "print(\"\\n‚úÖ Syst√®me pr√™t pour les tests!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56580b4d",
   "metadata": {},
   "source": [
    "<h1>Tests et D√©monstrations</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dee00760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ Profil utilisateur 1:\n",
      "   Nombre d'√©valuations: 3\n",
      "   Note moyenne: 4.00\n",
      "   Cat√©gories pr√©f√©r√©es: [3, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "user_id_test = 1\n",
    "profile = get_user_profile(user_id_test)\n",
    "print(f\"\\nüë§ Profil utilisateur {user_id_test}:\")\n",
    "print(f\"   Nombre d'√©valuations: {profile.get('total_ratings', 0)}\")\n",
    "print(f\"   Note moyenne: {profile.get('avg_rating', 0):.2f}\")\n",
    "print(f\"   Cat√©gories pr√©f√©r√©es: {list(profile.get('category_prefs', {}).keys())[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2c1d6",
   "metadata": {},
   "source": [
    "<h2> Recommandations pour un livre (remplacez 1 par un ID livre existant)\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "673a2e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Livre 1 dans le cluster 8 - 2 livres similaires\n",
      "‚ö†Ô∏è Pas assez de livres dans le cluster 8, recherche √©tendue...\n",
      "\n",
      "üìö Recommandations pour le livre 1:\n",
      "   1. 1984 - Score: 1.650\n",
      "   2. Candide - Score: 1.410\n",
      "   3. Fondation - Score: 0.840\n",
      "   4. Orgeuil Et Pr√©jug√©s - Score: 0.750\n",
      "   5. La M√©tamorphose - Score: 0.750\n"
     ]
    }
   ],
   "source": [
    "book_id_test = 1\n",
    "recommendations = get_recommendations(book_id_test, user_id=user_id_test, n_recommendations=5)\n",
    "print(f\"\\nüìö Recommandations pour le livre {book_id_test}:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"   {i}. {rec['title']} - Score: {rec['final_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b4669f",
   "metadata": {},
   "source": [
    "<h1>Recommandations intelligentes pour utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bfa03d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ D√©but recommandations intelligentes pour user 1\n",
      "üìä Chargement des donn√©es depuis MySQL...\n",
      "‚úÖ Donn√©es brutes charg√©es: 503 livres, 6 utilisateurs, 39 √©valuations\n",
      "üîç Analyse de la qualit√© des donn√©es...\n",
      "‚úÖ Analyse qualit√© termin√©e: 0 probl√®mes d√©tect√©s\n",
      "üßπ Nettoyage des donn√©es livres...\n",
      "‚úÖ Donn√©es nettoy√©es: 503 livres\n",
      "üìä Extraction de features avanc√©es...\n",
      "üìâ PCA appliqu√©: 8 composantes principales\n",
      "‚úÖ 12 features extraites pour 503 livres\n",
      "ü§ñ Entra√Ænement du mod√®le K-Means...\n",
      "üìä Utilisation de 15 clusters pour 503 livres\n",
      "üìà √âvaluation du clustering K-Means...\n",
      "‚úÖ √âvaluation termin√©e:\n",
      "   Silhouette: 0.242\n",
      "   Calinski-Harabasz: 129.1\n",
      "   Davies-Bouldin: 1.096\n",
      "   15 clusters, taille moyenne: 33.5\n",
      "‚úÖ Visualisation sauvegard√©e: clusters_visualization.png\n",
      "‚úÖ K-Means entra√Æn√© avec 15 clusters\n",
      "üìä M√©triques: Silhouette=0.242\n",
      "   Cluster 0: 72 livres\n",
      "   Cluster 1: 4 livres\n",
      "   Cluster 2: 48 livres\n",
      "   Cluster 3: 66 livres\n",
      "   Cluster 4: 2 livres\n",
      "   Cluster 5: 57 livres\n",
      "   Cluster 6: 69 livres\n",
      "   Cluster 7: 53 livres\n",
      "   Cluster 8: 3 livres\n",
      "   Cluster 9: 15 livres\n",
      "   Cluster 10: 5 livres\n",
      "   Cluster 11: 47 livres\n",
      "   Cluster 12: 8 livres\n",
      "   Cluster 13: 3 livres\n",
      "   Cluster 14: 51 livres\n",
      "üë§ Pr√©paration des profils utilisateurs...\n",
      "‚úÖ Profils cr√©√©s pour 6 utilisateurs\n",
      "üìö 503 livres disponibles dans 15 clusters\n",
      "‚úÖ Profil 1 recalcul√©: 3 √©valuations\n",
      "üìä Profil user 1: 3 √©valuations\n",
      "üéØ Clusters pr√©f√©r√©s: [8]\n",
      "‚ö†Ô∏è Strat√©gie: Inclure TOUS les livres (m√™me √©valu√©s) avec scores ajust√©s\n",
      "üìñ Livres √©valu√©s par user 1: 3\n",
      "üìö 503 livres √©valu√©s pour recommandation\n",
      "‚úÖ 8 recommandations FINALES pour user 1 (3 d√©j√† √©valu√©s, 5 nouveaux)\n",
      "\n",
      "üß† Recommandations intelligentes pour utilisateur 1:\n",
      "   1. 1984 - Score: 6.471\n",
      "      Raison: ‚≠ê Vous avez ador√© (4.0/5) - Cluster pr√©f√©r√© (8), Cat√©gorie pr√©f√©r√©e (vous avez not√© 4/5)\n",
      "   2. Le Petit Prince - Score: 5.587\n",
      "      Raison: ‚≠ê Vous avez ador√© (5.0/5) - Cluster pr√©f√©r√© (8), Cat√©gorie pr√©f√©r√©e (vous avez not√© 5/5)\n",
      "   3. Candide - Score: 5.277\n",
      "      Raison: üìñ D√©j√† lu (3.0/5) - Cluster pr√©f√©r√© (8), Budget adapt√©\n",
      "   4. Animal Farm - Score: 2.040\n",
      "      Raison: üéØ Recommandation personnalis√©e - Cat√©gorie pr√©f√©r√©e, Auteur appr√©ci√©\n",
      "   5. Harry Potter √Ä L'√âcole Des Sorciers - Score: 1.953\n",
      "      Raison: üëç Tr√®s bien not√© (5.0/5) - Cat√©gorie pr√©f√©r√©e, Budget adapt√©\n",
      "   6. Les Mis√©rables - Score: 1.581\n",
      "      Raison: üëç Tr√®s bien not√© (4.2/5) - Cat√©gorie pr√©f√©r√©e, Budget adapt√©\n",
      "   7. Orgeuil Et Pr√©jug√©s - Score: 1.454\n",
      "      Raison: üëç Tr√®s bien not√© (4.5/5) - Cat√©gorie pr√©f√©r√©e, Budget adapt√©\n",
      "   8. Le Comte De Monte-Cristo - Score: 1.409\n",
      "      Raison: üëç Tr√®s bien not√© (5.0/5) - Cat√©gorie pr√©f√©r√©e, Budget adapt√©\n"
     ]
    }
   ],
   "source": [
    "intelligent_recs = get_intelligent_recommendations(user_id_test, n_recommendations=8)\n",
    "print(f\"\\nüß† Recommandations intelligentes pour utilisateur {user_id_test}:\")\n",
    "for i, rec in enumerate(intelligent_recs, 1):\n",
    "    print(f\"   {i}. {rec['title']} - Score: {rec['score']:.3f}\")\n",
    "    print(f\"      Raison: {rec['reason']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f0763",
   "metadata": {},
   "source": [
    "<h1> √âvaluation compl√®te pour un utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2208f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_evaluation(user_id):\n",
    "    \"\"\"Ex√©cute une √©valuation compl√®te pour un utilisateur\"\"\"\n",
    "    print(f\"\\nüìä √âVALUATION COMPL√àTE POUR UTILISATEUR {user_id}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. √âvaluer le clustering\n",
    "    clustering_metrics = None\n",
    "    if book_features_matrix is not None and book_clusters:\n",
    "        clusters = []\n",
    "        valid_indices = []\n",
    "        for idx, book_id in index_to_book_id.items():\n",
    "            cluster_id = book_clusters.get(book_id, -1)\n",
    "            if cluster_id != -1:\n",
    "                clusters.append(cluster_id)\n",
    "                valid_indices.append(idx)\n",
    "        \n",
    "        if clusters:\n",
    "            clusters_array = np.array(clusters)\n",
    "            features_subset = book_features_matrix[valid_indices]\n",
    "            clustering_metrics = evaluate_clustering(features_subset, clusters_array)\n",
    "            print(f\"‚úÖ Clustering √©valu√©\")\n",
    "    \n",
    "    # 2. G√©n√©rer et √©valuer les recommandations\n",
    "    recommendations = get_intelligent_recommendations(user_id)\n",
    "    \n",
    "    # R√©cup√©rer l'historique\n",
    "    user_history = {'evaluated_books': []}\n",
    "    if ratings_df is not None:\n",
    "        user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
    "        user_history['evaluated_books'] = user_ratings['book_id'].tolist()\n",
    "    \n",
    "    rec_metrics = evaluate_recommendations(\n",
    "        recommendations,\n",
    "        user_history=user_history,\n",
    "        all_books=books_df['id'].tolist() if books_df is not None else []\n",
    "    )\n",
    "    \n",
    "    # 3. G√©n√©rer un rapport\n",
    "    report = generate_evaluation_report(\n",
    "        clustering_metrics=clustering_metrics,\n",
    "        recommendation_metrics=rec_metrics\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìà R√âSULTATS:\")\n",
    "    if clustering_metrics:\n",
    "        print(f\"   - Score Silhouette: {clustering_metrics.get('silhouette_score', 0):.3f}\")\n",
    "    print(f\"   - Couverture recommandations: {rec_metrics.get('coverage', 0):.1%}\")\n",
    "    print(f\"   - Diversit√© cat√©gories: {rec_metrics.get('category_diversity', 0):.1%}\")\n",
    "    print(f\"   - Nouveaut√©: {rec_metrics.get('novelty', 0):.1%}\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Ex√©cuter l'√©valuation\n",
    "evaluation_report = run_full_evaluation(user_id_test)\n",
    "\n",
    "# %%\n",
    "print(\"\\nüéØ NOTEBOOK TERMIN√â AVEC SUCC√àS!\")\n",
    "print(\"Vous pouvez maintenant ex√©cuter diff√©rentes cellules pour tester le syst√®me.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178a44ae",
   "metadata": {},
   "source": [
    "<h1>G√©n√©rer et √©valuer les recommandations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfd644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5002\n",
      " * Running on http://100.90.113.220:5002\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 12. Routes API Flask\n",
    "\n",
    "# %%\n",
    "# Initialisation de Flask\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# %%\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"API de Recommandation avec MySQL, K-Means et √âvaluation üöÄ\"\n",
    "\n",
    "# %%\n",
    "@app.route('/health')\n",
    "def health():\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'books': len(books_df) if books_df is not None else 0,\n",
    "        'users_with_profiles': len(user_features),\n",
    "        'clusters': len(set(book_clusters.values())) if book_clusters else 0,\n",
    "        'model': 'K-Means',\n",
    "        'evaluation_ready': len(evaluation_history) > 0\n",
    "    })\n",
    "\n",
    "# %%\n",
    "@app.route('/initialize', methods=['POST'])\n",
    "def initialize():\n",
    "    \"\"\"Initialise le mod√®le\"\"\"\n",
    "    try:\n",
    "        load_data_from_db()\n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'message': f'Mod√®le initialis√© avec {len(books_df)} livres et {len(user_features)} profils',\n",
    "            'clusters': len(set(book_clusters.values())) if book_clusters else 0,\n",
    "            'data_quality_issues': len(data_quality_report.get('issues', []))\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/recommend/<int:book_id>', methods=['GET'])\n",
    "def recommend(book_id):\n",
    "    \"\"\"Recommandations pour un livre\"\"\"\n",
    "    try:\n",
    "        user_id = request.args.get('user_id', type=int)\n",
    "        \n",
    "        recommendations = get_recommendations(\n",
    "            book_id, \n",
    "            user_id=user_id,\n",
    "            n_recommendations=8\n",
    "        )\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'recommendations': recommendations,\n",
    "            'count': len(recommendations),\n",
    "            'model': 'K-Means'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur route /recommend: {e}\")\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/intelligent-recommendations/<int:user_id>', methods=['GET'])\n",
    "def intelligent_recommendations(user_id):\n",
    "    \"\"\"Recommandations intelligentes bas√©es sur les pr√©f√©rences\"\"\"\n",
    "    try:\n",
    "        print(f\"üß† D√©but recommandations intelligentes pour user {user_id}\")\n",
    "        \n",
    "        # Forcer le chargement des donn√©es\n",
    "        load_data_from_db()\n",
    "        \n",
    "        if books_df is None or books_df.empty:\n",
    "            print(\"‚ùå Pas de livres dans la base\")\n",
    "            return jsonify({\n",
    "                'status': 'success',\n",
    "                'recommendations': [],\n",
    "                'count': 0,\n",
    "                'message': 'Base de donn√©es vide'\n",
    "            })\n",
    "        \n",
    "        print(f\"üìö {len(books_df)} livres disponibles\")\n",
    "        \n",
    "        # Obtenir les recommandations\n",
    "        recommendations = get_intelligent_recommendations(user_id)\n",
    "        \n",
    "        print(f\"‚úÖ {len(recommendations)} recommandations g√©n√©r√©es\")\n",
    "        \n",
    "        # Formater la r√©ponse\n",
    "        formatted_recommendations = []\n",
    "        for rec in recommendations:\n",
    "            formatted_rec = {\n",
    "                'id': rec['id'],\n",
    "                'title': rec['title'],\n",
    "                'author': rec['author'],\n",
    "                'reason': rec.get('reason', 'Recommand√© pour vous'),\n",
    "                'category_id': rec.get('category_id', 0),\n",
    "                'price': rec.get('price', 0),\n",
    "                'image_url': rec.get('image_url', f'https://via.placeholder.com/220x300?text={rec[\"title\"]}'),\n",
    "                'score': rec.get('score', 0.5)\n",
    "            }\n",
    "            formatted_recommendations.append(formatted_rec)\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'recommendations': formatted_recommendations,\n",
    "            'count': len(formatted_recommendations),\n",
    "            'algorithm': 'intelligent',\n",
    "            'model': 'K-Means',\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'books_in_db': len(books_df)\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur route recommandations intelligentes: {e}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Fallback\n",
    "        fallback_recs = get_enhanced_fallback_recommendations()\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'recommendations': fallback_recs,\n",
    "            'count': len(fallback_recs),\n",
    "            'algorithm': 'fallback',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "# %%\n",
    "@app.route('/data-quality', methods=['GET'])\n",
    "def get_data_quality():\n",
    "    \"\"\"Retourne le rapport de qualit√© des donn√©es\"\"\"\n",
    "    try:\n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'quality_report': data_quality_report\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/evaluate/clustering', methods=['GET'])\n",
    "def evaluate_clustering_route():\n",
    "    \"\"\"√âvalue le clustering\"\"\"\n",
    "    try:\n",
    "        if book_features_matrix is None or not book_clusters:\n",
    "            return jsonify({'status': 'error', 'message': 'Clustering non disponible'}), 400\n",
    "        \n",
    "        # Pr√©parer les donn√©es\n",
    "        clusters = []\n",
    "        valid_indices = []\n",
    "        \n",
    "        for idx, book_id in index_to_book_id.items():\n",
    "            cluster_id = book_clusters.get(book_id, -1)\n",
    "            if cluster_id != -1:\n",
    "                clusters.append(cluster_id)\n",
    "                valid_indices.append(idx)\n",
    "        \n",
    "        if not clusters:\n",
    "            return jsonify({'status': 'error', 'message': 'Aucun cluster valide'}), 400\n",
    "        \n",
    "        clusters_array = np.array(clusters)\n",
    "        features_subset = book_features_matrix[valid_indices]\n",
    "        \n",
    "        # √âvaluer\n",
    "        metrics = evaluate_clustering(features_subset, clusters_array)\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'metrics': metrics,\n",
    "            'model': 'K-Means'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/evaluate/recommendations/<int:user_id>', methods=['GET'])\n",
    "def evaluate_user_recommendations(user_id):\n",
    "    \"\"\"√âvalue les recommandations pour un utilisateur\"\"\"\n",
    "    try:\n",
    "        n_recommendations = request.args.get('n', default=10, type=int)\n",
    "        \n",
    "        # G√©n√©rer les recommandations\n",
    "        recommendations = get_intelligent_recommendations(user_id, n_recommendations)\n",
    "        \n",
    "        # R√©cup√©rer l'historique\n",
    "        user_history = {'evaluated_books': []}\n",
    "        if ratings_df is not None:\n",
    "            user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
    "            user_history['evaluated_books'] = user_ratings['book_id'].tolist()\n",
    "        \n",
    "        # √âvaluer\n",
    "        rec_metrics = evaluate_recommendations(\n",
    "            recommendations,\n",
    "            user_history=user_history,\n",
    "            all_books=books_df['id'].tolist() if books_df is not None else []\n",
    "        )\n",
    "        \n",
    "        # G√©n√©rer un rapport\n",
    "        report = generate_evaluation_report(\n",
    "            clustering_metrics=None,\n",
    "            recommendation_metrics=rec_metrics\n",
    "        )\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'evaluation': {\n",
    "                'recommendations': rec_metrics,\n",
    "                'report': report\n",
    "            },\n",
    "            'user_id': user_id\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/debug/full/<int:user_id>', methods=['GET'])\n",
    "def debug_full(user_id):\n",
    "    \"\"\"Debug complet avec √©valuation\"\"\"\n",
    "    try:\n",
    "        # 1. Recharger les donn√©es\n",
    "        load_data_from_db()\n",
    "        \n",
    "        # 2. √âvaluer le clustering\n",
    "        clustering_metrics = None\n",
    "        if book_features_matrix is not None and book_clusters:\n",
    "            clusters = []\n",
    "            valid_indices = []\n",
    "            for idx, book_id in index_to_book_id.items():\n",
    "                cluster_id = book_clusters.get(book_id, -1)\n",
    "                if cluster_id != -1:\n",
    "                    clusters.append(cluster_id)\n",
    "                    valid_indices.append(idx)\n",
    "            \n",
    "            if clusters:\n",
    "                clusters_array = np.array(clusters)\n",
    "                features_subset = book_features_matrix[valid_indices]\n",
    "                clustering_metrics = evaluate_clustering(features_subset, clusters_array)\n",
    "        \n",
    "        # 3. G√©n√©rer des recommandations\n",
    "        recommendations = get_intelligent_recommendations(user_id)\n",
    "        \n",
    "        # 4. √âvaluer les recommandations\n",
    "        user_history = {'evaluated_books': []}\n",
    "        if ratings_df is not None:\n",
    "            user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
    "            user_history['evaluated_books'] = user_ratings['book_id'].tolist()\n",
    "        \n",
    "        rec_metrics = evaluate_recommendations(\n",
    "            recommendations,\n",
    "            user_history=user_history,\n",
    "            all_books=books_df['id'].tolist() if books_df is not None else []\n",
    "        )\n",
    "        \n",
    "        # 5. Rapport complet\n",
    "        report = generate_evaluation_report(\n",
    "            clustering_metrics=clustering_metrics,\n",
    "            recommendation_metrics=rec_metrics\n",
    "        )\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'user_id': user_id,\n",
    "            'clustering_evaluation': clustering_metrics,\n",
    "            'recommendation_evaluation': rec_metrics,\n",
    "            'full_report': report,\n",
    "            'data_quality': data_quality_report,\n",
    "            'n_recommendations': len(recommendations)\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/user-profile/<int:user_id>', methods=['GET'])\n",
    "def user_profile(user_id):\n",
    "    \"\"\"R√©cup√®re le profil utilisateur\"\"\"\n",
    "    try:\n",
    "        profile = get_user_profile(user_id)\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'profile': {\n",
    "                'user_id': user_id,\n",
    "                'avg_rating': profile['avg_rating'],\n",
    "                'total_ratings': profile['total_ratings'],\n",
    "                'preferred_categories': list(profile['category_prefs'].keys())[:3],\n",
    "                'preferred_authors': list(profile['author_prefs'].keys())[:5],\n",
    "                'price_range': profile['preferred_price_range'],\n",
    "                'last_updated': profile['last_updated']\n",
    "            }\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur route /user-profile: {e}\")\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/refresh-profile/<int:user_id>', methods=['POST'])\n",
    "def refresh_profile(user_id):\n",
    "    \"\"\"Force le rafra√Æchissement du profil\"\"\"\n",
    "    try:\n",
    "        recalculate_user_profile(user_id)\n",
    "        \n",
    "        if user_id in user_features:\n",
    "            return jsonify({\n",
    "                'status': 'success',\n",
    "                'message': f'Profil {user_id} rafra√Æchi',\n",
    "                'profile': get_user_profile(user_id)\n",
    "            })\n",
    "        else:\n",
    "            return jsonify({'status': 'error', 'message': 'Erreur rafra√Æchissement'}), 500\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur route /refresh-profile: {e}\")\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/clusters/visualization', methods=['GET'])\n",
    "def get_clusters_visualization():\n",
    "    \"\"\"Retourne la visualisation des clusters\"\"\"\n",
    "    try:\n",
    "        if book_features_matrix is None or not book_clusters:\n",
    "            return jsonify({'status': 'error', 'message': 'Clustering non disponible'}), 400\n",
    "        \n",
    "        # Pr√©parer les donn√©es pour la visualisation\n",
    "        clusters = []\n",
    "        valid_indices = []\n",
    "        for idx, book_id in index_to_book_id.items():\n",
    "            cluster_id = book_clusters.get(book_id, -1)\n",
    "            if cluster_id != -1:\n",
    "                clusters.append(cluster_id)\n",
    "                valid_indices.append(idx)\n",
    "        \n",
    "        if not clusters:\n",
    "            return jsonify({'status': 'error', 'message': 'Aucun cluster valide'}), 400\n",
    "        \n",
    "        clusters_array = np.array(clusters)\n",
    "        features_subset = book_features_matrix[valid_indices]\n",
    "        \n",
    "        # Cr√©er la visualisation\n",
    "        save_path = \"static/clusters_visualization.png\"\n",
    "        success = visualize_clusters(features_subset, clusters_array, save_path)\n",
    "        \n",
    "        if success:\n",
    "            return jsonify({\n",
    "                'status': 'success',\n",
    "                'visualization_url': f'/{save_path}',\n",
    "                'message': 'Visualisation cr√©√©e avec succ√®s'\n",
    "            })\n",
    "        else:\n",
    "            return jsonify({'status': 'error', 'message': 'Erreur cr√©ation visualisation'}), 500\n",
    "            \n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/recommendations/fallback', methods=['GET'])\n",
    "def get_fallback_recommendations():\n",
    "    \"\"\"Retourne des recommandations fallback\"\"\"\n",
    "    try:\n",
    "        recommendations = get_enhanced_fallback_recommendations()\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'recommendations': recommendations,\n",
    "            'count': len(recommendations),\n",
    "            'algorithm': 'fallback'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500   \n",
    "app.run(host='0.0.0.0', port=5002, debug=True, use_reloader=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
