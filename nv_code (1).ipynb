{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae6d2a91",
   "metadata": {},
   "source": [
    "<h1>Introduction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44b5c5a",
   "metadata": {},
   "source": [
    "<p>Ce projet est un système de recommandation de livres intelligent basé sur l'apprentissage automatique (machine learning) qui utilise l'algorithme K-Means pour le clustering et une API REST Flask pour servir les recommandations. Le système est conçu pour analyser les préférences des utilisateurs et recommander des livres pertinents en fonction de leurs habitudes de lecture, de leurs évaluations passées et des caractéristiques des livres.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715aca12",
   "metadata": {},
   "source": [
    "<h1>Importations</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23ac010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from flask import Flask, request, jsonify\n",
    "import mysql.connector\n",
    "from flask_cors import CORS\n",
    "from mysql.connector import Error\n",
    "from contextlib import contextmanager\n",
    "import traceback\n",
    "import warnings# Manipulation de données en tables (DataFrames)\n",
    "import pandas as pd\n",
    "\n",
    "# Calculs numériques, matrices, tableaux\n",
    "import numpy as np\n",
    "\n",
    "# Prétraitement : standardisation des données et encodage des labels catégoriels\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Algorithme de clustering non supervisé\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Mesures d’évaluation de clustering\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "# Réduction de dimensionnalité\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualisation graphique (plots, graphiques)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Création d'une API web légère\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "# Connexion à une base de données MySQL\n",
    "import mysql.connector\n",
    "\n",
    "# Autoriser les requêtes Cross-Origin (CORS) sur l’API Flask\n",
    "from flask_cors import CORS\n",
    "\n",
    "# Gestion des erreurs spécifiques à MySQL\n",
    "from mysql.connector import Error\n",
    "\n",
    "# Contexte manager pour gérer proprement les ressources (ex: connexions)\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Gestion et affichage des traces d’erreurs\n",
    "import traceback\n",
    "\n",
    "# Ignorer certains avertissements (warnings)\n",
    "import warnings\n",
    "\n",
    "# Manipulation des dates et heures\n",
    "from datetime import datetime\n",
    "\n",
    "# Lecture et écriture de données au format JSON\n",
    "import json\n",
    "\n",
    "# Désactiver les warnings pour un affichage plus propre\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime\n",
    "import json\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece97b5f",
   "metadata": {},
   "source": [
    "### Silhouette Score\n",
    "\n",
    "Pour un point \\( i \\) :\n",
    "\n",
    "- \\( a(i) \\) = moyenne des distances entre \\( i \\) et les autres points du même cluster.\n",
    "- \\( b(i) \\) = plus petite moyenne des distances entre \\( i \\) et les autres clusters.\n",
    "\n",
    "Le score de silhouette pour le point \\( i \\) est :\n",
    "\n",
    "$$\n",
    "s(i) = \\frac{b(i) - a(i)}{\\max(a(i), b(i))}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b959b8",
   "metadata": {},
   "source": [
    "### 2. Calinski-Harabasz Score (Indice de Calinski-Harabasz)\n",
    "\n",
    "Considérons un jeu de données avec \\( n \\) points et \\( k \\) clusters.\n",
    "\n",
    "- \\( S_B \\) = dispersion entre les clusters (between-cluster scatter matrix).\n",
    "- \\( S_W \\) = dispersion à l’intérieur des clusters (within-cluster scatter matrix).\n",
    "\n",
    "Le score est défini par :\n",
    "\n",
    "$$\n",
    "CH = \\frac{\\operatorname{trace}(S_B)}{\\operatorname{trace}(S_W)} \\times \\frac{n - k}{k - 1}\n",
    "$$\n",
    "\n",
    "Plus ce score est élevé, meilleur est le clustering (clusters bien séparés et compacts).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Davies-Bouldin Score\n",
    "\n",
    "Pour chaque cluster \\( i \\), on calcule :\n",
    "\n",
    "- \\( S_i \\) = mesure de dispersion (ex. moyenne des distances des points du cluster \\( i \\) à son centre).\n",
    "- \\( M_{ij} \\) = distance entre les centres des clusters \\( i \\) et \\( j \\).\n",
    "\n",
    "Pour chaque cluster \\( i \\), on définit :\n",
    "\n",
    "$$\n",
    "R_{ij} = \\frac{S_i + S_j}{M_{ij}}\n",
    "$$\n",
    "\n",
    "Le score de Davies-Bouldin pour le cluster \\( i \\) est :\n",
    "\n",
    "$$\n",
    "R_i = \\max_{j \\neq i} R_{ij}\n",
    "$$\n",
    "\n",
    "Le score global est la moyenne sur tous les clusters :\n",
    "\n",
    "$$\n",
    "DB = \\frac{1}{k} \\sum_{i=1}^k R_i\n",
    "$$\n",
    "\n",
    "Un score DB plus faible indique un meilleur clustering (clusters bien séparés et peu dispersés).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11355675",
   "metadata": {},
   "source": [
    "<h1>Configuration Initiale</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23e09992",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '',\n",
    "    'database': 'reco_db'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4cf6bd",
   "metadata": {},
   "source": [
    "<h1>Variables globales (initialisation)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "45b2347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = None\n",
    "ratings_df = None\n",
    "users_df = None\n",
    "cart_df = None\n",
    "user_features = {}\n",
    "book_features_matrix = None\n",
    "book_id_to_index = {}\n",
    "index_to_book_id = {}\n",
    "book_clusters = {}\n",
    "kmeans_model = None\n",
    "scaler = StandardScaler()\n",
    "category_encoder = LabelEncoder()\n",
    "author_encoder = LabelEncoder()\n",
    "data_quality_report = {}\n",
    "evaluation_history = []\n",
    "feature_names = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a86c65",
   "metadata": {},
   "source": [
    "<h1>Fonctions d'Analyse de Données</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f11c9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data_quality():\n",
    "    \"\"\"Analyse la qualité des données\"\"\"\n",
    "    print(\" Analyse de la qualité des données...\")\n",
    "    \n",
    "    quality_report = {\n",
    "        'books': {},\n",
    "        'ratings': {},\n",
    "        'users': {},\n",
    "        'issues': []\n",
    "    }\n",
    "    \n",
    "    # Analyse des livres\n",
    "    if books_df is not None and not books_df.empty:\n",
    "        quality_report['books']['total'] = len(books_df)\n",
    "        quality_report['books']['missing_values'] = books_df.isnull().sum().to_dict()\n",
    "        quality_report['books']['duplicates'] = books_df.duplicated(subset=['title', 'author']).sum()\n",
    "        \n",
    "        # Détecter les problèmes\n",
    "        if 'price' in books_df.columns:\n",
    "            if books_df['price'].min() <= 0:\n",
    "                quality_report['issues'].append(\"Prix non valides (≤ 0) détectés\")\n",
    "        if 'stock' in books_df.columns:\n",
    "            if books_df['stock'].min() < 0:\n",
    "                quality_report['issues'].append(\"Stocks négatifs détectés\")\n",
    "    \n",
    "    # Analyse des évaluations\n",
    "    if ratings_df is not None and not ratings_df.empty:\n",
    "        quality_report['ratings']['total'] = len(ratings_df)\n",
    "        quality_report['ratings']['missing_values'] = ratings_df.isnull().sum().to_dict()\n",
    "        quality_report['ratings']['rating_range'] = {\n",
    "            'min': ratings_df['rating'].min(),\n",
    "            'max': ratings_df['rating'].max(),\n",
    "            'mean': ratings_df['rating'].mean()\n",
    "        }\n",
    "        quality_report['ratings']['unique_users'] = ratings_df['user_id'].nunique()\n",
    "        quality_report['ratings']['unique_books'] = ratings_df['book_id'].nunique()\n",
    "        \n",
    "        # Vérifier les évaluations non valides\n",
    "        invalid_ratings = ratings_df[(ratings_df['rating'] < 1) | (ratings_df['rating'] > 5)]\n",
    "        if len(invalid_ratings) > 0:\n",
    "            quality_report['issues'].append(f\"{len(invalid_ratings)} évaluations hors plage [1,5]\")\n",
    "    \n",
    "    # Analyse des utilisateurs\n",
    "    if users_df is not None and not users_df.empty:\n",
    "        quality_report['users']['total'] = len(users_df)\n",
    "        quality_report['users']['missing_values'] = users_df.isnull().sum().to_dict()\n",
    "    \n",
    "    print(f\" Analyse qualité terminée: {len(quality_report['issues'])} problèmes détectés\")\n",
    "    return quality_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94768804",
   "metadata": {},
   "source": [
    "<h1>Nettoyage des données</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "251819bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_books_data(df):\n",
    "    \"\"\"Nettoyage avancé des données livres\"\"\"\n",
    "    print(\" Nettoyage des données livres...\")\n",
    "    \n",
    "    # Copie pour éviter les warnings\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # 1. Gestion des valeurs manquantes\n",
    "    if 'price' in cleaned_df.columns:\n",
    "        cleaned_df['price'] = pd.to_numeric(cleaned_df['price'], errors='coerce')\n",
    "        median_price = cleaned_df['price'].median()\n",
    "        cleaned_df['price'] = cleaned_df['price'].fillna(median_price)\n",
    "        \n",
    "        # Remplacer les prix non valides\n",
    "        cleaned_df.loc[cleaned_df['price'] <= 0, 'price'] = median_price\n",
    "    \n",
    "    if 'stock' in cleaned_df.columns:\n",
    "        cleaned_df['stock'] = pd.to_numeric(cleaned_df['stock'], errors='coerce')\n",
    "        median_stock = cleaned_df['stock'].median()\n",
    "        cleaned_df['stock'] = cleaned_df['stock'].fillna(median_stock)\n",
    "        cleaned_df.loc[cleaned_df['stock'] < 0, 'stock'] = 0\n",
    "    \n",
    "    # 2. Normalisation du texte\n",
    "    if 'title' in cleaned_df.columns:\n",
    "        cleaned_df['title'] = cleaned_df['title'].str.strip().str.title()\n",
    "    \n",
    "    if 'author' in cleaned_df.columns:\n",
    "        cleaned_df['author'] = cleaned_df['author'].str.strip().str.title()\n",
    "        \n",
    "        # Encodage des auteurs\n",
    "        try:\n",
    "            cleaned_df['author_encoded'] = author_encoder.fit_transform(cleaned_df['author'])\n",
    "        except:\n",
    "            cleaned_df['author_encoded'] = 0\n",
    "    \n",
    "    # 3. Gestion des catégories\n",
    "    if 'category_id' in cleaned_df.columns:\n",
    "        # Remplacer les catégories manquantes\n",
    "        mode_category = cleaned_df['category_id'].mode()[0] if not cleaned_df['category_id'].mode().empty else 1\n",
    "        cleaned_df['category_id'] = cleaned_df['category_id'].fillna(mode_category)\n",
    "        \n",
    "        # Encodage\n",
    "        cleaned_df['category_encoded'] = category_encoder.fit_transform(\n",
    "            cleaned_df['category_id'].astype(str)\n",
    "        )\n",
    "    \n",
    "    # 4. Extraction de features textuelles\n",
    "    if 'title' in cleaned_df.columns:\n",
    "        cleaned_df['title_length'] = cleaned_df['title'].str.len()\n",
    "        cleaned_df['word_count'] = cleaned_df['title'].str.split().str.len()\n",
    "    \n",
    "    # 5. Features temporelles si disponible\n",
    "    if 'year' in cleaned_df.columns:\n",
    "        cleaned_df['year'] = pd.to_numeric(cleaned_df['year'], errors='coerce')\n",
    "        current_year = datetime.now().year\n",
    "        cleaned_df['age'] = current_year - cleaned_df['year'].fillna(current_year)\n",
    "        cleaned_df['age'] = cleaned_df['age'].clip(lower=0, upper=100)\n",
    "    \n",
    "    print(f\" Données nettoyées: {len(cleaned_df)} livres\")\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ebca8",
   "metadata": {},
   "source": [
    "<h1>Extraction de features</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ea56a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_book_features():\n",
    "    \"\"\"Extraction avancée de features pour les livres\"\"\"\n",
    "    print(\" Extraction de features avancées...\")\n",
    "    \n",
    "    global feature_names, book_features_matrix, book_id_to_index, index_to_book_id\n",
    "    \n",
    "    features_list = []\n",
    "    book_ids = []\n",
    "    \n",
    "    for _, book in books_df.iterrows():\n",
    "        book_id = book['id']\n",
    "        book_features = {}\n",
    "        \n",
    "        # 1. Features basiques\n",
    "        book_features['price'] = float(book['price'])\n",
    "        book_features['stock'] = float(book['stock'])\n",
    "        book_features['category_encoded'] = float(book.get('category_encoded', 0))\n",
    "        book_features['author_encoded'] = float(book.get('author_encoded', 0))\n",
    "        \n",
    "        # 2. Features de popularité\n",
    "        if ratings_df is not None and not ratings_df.empty:\n",
    "            book_ratings = ratings_df[ratings_df['book_id'] == book_id]\n",
    "            rating_count = len(book_ratings)\n",
    "            avg_rating = book_ratings['rating'].mean() if rating_count > 0 else 3.0\n",
    "            \n",
    "            book_features['avg_rating'] = float(avg_rating)\n",
    "            book_features['rating_count'] = float(rating_count)\n",
    "            book_features['popularity'] = float(avg_rating * np.log1p(rating_count + 1))\n",
    "            \n",
    "            # Variabilité des notes\n",
    "            if rating_count > 1:\n",
    "                rating_std = book_ratings['rating'].std()\n",
    "                book_features['rating_std'] = float(rating_std)\n",
    "            else:\n",
    "                book_features['rating_std'] = 0.0\n",
    "        else:\n",
    "            book_features['avg_rating'] = 3.0\n",
    "            book_features['rating_count'] = 0.0\n",
    "            book_features['popularity'] = 0.0\n",
    "            book_features['rating_std'] = 0.0\n",
    "        \n",
    "        # 3. Features textuelles\n",
    "        book_features['title_length'] = float(book.get('title_length', 0))\n",
    "        book_features['word_count'] = float(book.get('word_count', 0))\n",
    "        \n",
    "        # 4. Features temporelles\n",
    "        book_features['age'] = float(book.get('age', 0))\n",
    "        \n",
    "        # 5. Feature de disponibilité\n",
    "        book_features['available'] = float(book['stock'] > 0) if 'stock' in book else 1.0\n",
    "        \n",
    "        # Convertir en liste dans l'ordre fixe\n",
    "        feature_names = [\n",
    "            'price', 'stock', 'category_encoded', 'author_encoded',\n",
    "            'avg_rating', 'rating_count', 'popularity', 'rating_std',\n",
    "            'title_length', 'word_count', 'age', 'available'\n",
    "        ]\n",
    "        \n",
    "        features_vector = [book_features.get(name, 0.0) for name in feature_names]\n",
    "        \n",
    "        features_list.append(features_vector)\n",
    "        book_ids.append(book_id)\n",
    "    \n",
    "    features_matrix = np.array(features_list)\n",
    "    \n",
    "    # Normalisation\n",
    "    if len(features_list) > 1:\n",
    "        features_matrix = scaler.fit_transform(features_matrix)\n",
    "    \n",
    "    # Réduction de dimensionnalité\n",
    "    if features_matrix.shape[1] > 8:\n",
    "        pca = PCA(n_components=8)\n",
    "        features_matrix = pca.fit_transform(features_matrix)\n",
    "        print(f\" PCA appliqué: {features_matrix.shape[1]} composantes principales\")\n",
    "    \n",
    "    book_features_matrix = features_matrix\n",
    "    book_id_to_index = {book_id: idx for idx, book_id in enumerate(book_ids)}\n",
    "    index_to_book_id = {idx: book_id for idx, book_id in enumerate(book_ids)}\n",
    "    \n",
    "    print(f\"{len(feature_names)} features extraites pour {len(book_ids)} livres\")\n",
    "    \n",
    "    return features_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f5a3e",
   "metadata": {},
   "source": [
    "<h1>Détection des outliers</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f3c71c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(features_matrix, threshold=3):\n",
    "    \"\"\"Détection des outliers\"\"\"\n",
    "    print(\"Détection des outliers...\")\n",
    "    \n",
    "    # Méthode simple: distance à la médiane\n",
    "    median = np.median(features_matrix, axis=0)\n",
    "    mad = np.median(np.abs(features_matrix - median), axis=0)\n",
    "    \n",
    "    # Éviter la division par zéro\n",
    "    mad[mad == 0] = 1\n",
    "    \n",
    "    # Score Z modifié\n",
    "    modified_z_scores = 0.6745 * (features_matrix - median) / mad\n",
    "    \n",
    "    # Identifier les outliers\n",
    "    outlier_mask = np.any(np.abs(modified_z_scores) > threshold, axis=1)\n",
    "    outlier_count = np.sum(outlier_mask)\n",
    "    \n",
    "    print(f\" {outlier_count} outliers détectés ({outlier_count/len(features_matrix):.1%})\")\n",
    "    \n",
    "    return outlier_mask, outlier_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7e4fda",
   "metadata": {},
   "source": [
    "<h1> Évaluation du clustering </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d07e5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clustering(features_matrix, labels, model_name=\"K-Means\"):\n",
    "    \"\"\"Évalue la qualité du clustering\"\"\"\n",
    "    print(f\" Évaluation du clustering {model_name}...\")\n",
    "    \n",
    "    if len(np.unique(labels)) < 2:\n",
    "        print(\" Pas assez de clusters pour l'évaluation\")\n",
    "        return {}\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    try:\n",
    "        # 1. Silhouette Score (-1 à 1, plus haut = mieux)\n",
    "        silhouette = silhouette_score(features_matrix, labels)\n",
    "        metrics['silhouette_score'] = float(silhouette)\n",
    "        \n",
    "        # 2. Calinski-Harabasz Index (plus haut = mieux)\n",
    "        calinski = calinski_harabasz_score(features_matrix, labels)\n",
    "        metrics['calinski_harabasz'] = float(calinski)\n",
    "        \n",
    "        # 3. Davies-Bouldin Index (plus bas = mieux)\n",
    "        davies = davies_bouldin_score(features_matrix, labels)\n",
    "        metrics['davies_bouldin'] = float(davies)\n",
    "        \n",
    "        # 4. Distribution des clusters\n",
    "        unique, counts = np.unique(labels, return_counts=True)\n",
    "        metrics['cluster_distribution'] = dict(zip(map(int, unique), map(int, counts)))\n",
    "        metrics['n_clusters'] = int(len(unique))\n",
    "        \n",
    "        # 5. Taille des clusters\n",
    "        metrics['cluster_sizes'] = {\n",
    "            'min': int(np.min(counts)),\n",
    "            'max': int(np.max(counts)),\n",
    "            'mean': float(np.mean(counts)),\n",
    "            'std': float(np.std(counts))\n",
    "        }\n",
    "        \n",
    "        # 6. Coherence intra-cluster\n",
    "        intra_cluster_distances = []\n",
    "        for cluster_id in unique:\n",
    "            cluster_points = features_matrix[labels == cluster_id]\n",
    "            if len(cluster_points) > 1:\n",
    "                centroid = np.mean(cluster_points, axis=0)\n",
    "                distances = np.linalg.norm(cluster_points - centroid, axis=1)\n",
    "                intra_cluster_distances.extend(distances)\n",
    "        \n",
    "        if intra_cluster_distances:\n",
    "            metrics['intra_cluster_distance'] = {\n",
    "                'mean': float(np.mean(intra_cluster_distances)),\n",
    "                'std': float(np.std(intra_cluster_distances))\n",
    "            }\n",
    "        \n",
    "        # Interprétation\n",
    "        interpretations = []\n",
    "        \n",
    "        if silhouette > 0.7:\n",
    "            interpretations.append(\"Clusters bien séparés et denses\")\n",
    "        elif silhouette > 0.5:\n",
    "            interpretations.append(\"Clusters raisonnablement séparés\")\n",
    "        elif silhouette > 0.25:\n",
    "            interpretations.append(\"Clusters faibles, certains points mal assignés\")\n",
    "        else:\n",
    "            interpretations.append(\"Clusters peu définis\")\n",
    "        \n",
    "        if davies < 0.5:\n",
    "            interpretations.append(\"Faible chevauchement entre clusters\")\n",
    "        elif davies < 1.0:\n",
    "            interpretations.append(\"Chevauchement modéré entre clusters\")\n",
    "        else:\n",
    "            interpretations.append(\"Fort chevauchement entre clusters\")\n",
    "        \n",
    "        metrics['interpretation'] = interpretations\n",
    "        \n",
    "        print(f\" Évaluation terminée:\")\n",
    "        print(f\"   Silhouette: {silhouette:.3f}\")\n",
    "        print(f\"   Calinski-Harabasz: {calinski:.1f}\")\n",
    "        print(f\"   Davies-Bouldin: {davies:.3f}\")\n",
    "        print(f\"   {len(unique)} clusters, taille moyenne: {np.mean(counts):.1f}\")\n",
    "        \n",
    "        # Stocker dans l'historique\n",
    "        evaluation_history.append({\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'type': 'clustering',\n",
    "            'metrics': metrics\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur évaluation clustering: {e}\")\n",
    "        metrics['error'] = str(e)\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a68a49",
   "metadata": {},
   "source": [
    "<h1>Évalue la qualité des recommandations</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ed8788d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(recommendations, user_history=None, all_books=None):\n",
    "    \"\"\"Évalue la qualité des recommandations\"\"\"\n",
    "    print(\"Évaluation des recommandations...\")\n",
    "    \n",
    "    if not recommendations:\n",
    "        return {\n",
    "            'coverage': 0,\n",
    "            'diversity': 0,\n",
    "            'novelty': 0,\n",
    "            'serendipity': 0\n",
    "        }\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    # 1. Couverture (nombre unique de livres recommandés / total livres)\n",
    "    if all_books is not None:\n",
    "        recommended_ids = [r['id'] for r in recommendations if isinstance(r, dict) and 'id' in r]\n",
    "        unique_recommended = set(recommended_ids)\n",
    "        metrics['coverage'] = len(unique_recommended) / len(all_books) if len(all_books) > 0 else 0\n",
    "        metrics['unique_recommended'] = len(unique_recommended)\n",
    "        metrics['total_books'] = len(all_books)\n",
    "    \n",
    "    # 2. Diversité (basée sur les catégories)\n",
    "    categories = []\n",
    "    authors = []\n",
    "    for rec in recommendations:\n",
    "        if isinstance(rec, dict):\n",
    "            if 'category_id' in rec:\n",
    "                categories.append(rec['category_id'])\n",
    "            if 'author' in rec:\n",
    "                authors.append(rec['author'])\n",
    "    \n",
    "    if categories:\n",
    "        metrics['category_diversity'] = len(set(categories)) / len(categories) if categories else 0\n",
    "    if authors:\n",
    "        metrics['author_diversity'] = len(set(authors)) / len(authors) if authors else 0\n",
    "    \n",
    "    # 3. Nouveauté (recommandations non vues par l'utilisateur)\n",
    "    if user_history is not None:\n",
    "        user_book_ids = set(user_history.get('evaluated_books', []))\n",
    "        new_recommendations = [r for r in recommendations \n",
    "                             if isinstance(r, dict) and r.get('id') not in user_book_ids]\n",
    "        metrics['novelty'] = len(new_recommendations) / len(recommendations) if recommendations else 0\n",
    "    \n",
    "    # 4. Score moyen\n",
    "    if recommendations and 'score' in recommendations[0]:\n",
    "        scores = [r.get('score', 0) for r in recommendations]\n",
    "        metrics['score_distribution'] = {\n",
    "            'min': float(np.min(scores)),\n",
    "            'max': float(np.max(scores)),\n",
    "            'mean': float(np.mean(scores)),\n",
    "            'std': float(np.std(scores))\n",
    "        }\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7f557b",
   "metadata": {},
   "source": [
    "<h1>Génère un rapport d'évaluation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a04850d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_evaluation_report(clustering_metrics=None, recommendation_metrics=None):\n",
    "    \"\"\"Génère un rapport d'évaluation\"\"\"\n",
    "    print(\"Génération du rapport d'évaluation...\")\n",
    "    \n",
    "    report = {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'clustering': clustering_metrics or {},\n",
    "        'recommendations': recommendation_metrics or {},\n",
    "        'summary': {},\n",
    "        'data_quality': data_quality_report\n",
    "    }\n",
    "    \n",
    "    # Résumé clustering\n",
    "    if clustering_metrics:\n",
    "        report['summary']['clustering'] = {\n",
    "            'n_clusters': clustering_metrics.get('n_clusters', 0),\n",
    "            'silhouette_score': clustering_metrics.get('silhouette_score', 0),\n",
    "            'quality': clustering_metrics.get('interpretation', ['Non évalué'])[0] if clustering_metrics.get('interpretation') else 'Non évalué'\n",
    "        }\n",
    "    \n",
    "    # Résumé recommandations\n",
    "    if recommendation_metrics:\n",
    "        report['summary']['recommendations'] = {\n",
    "            'coverage': recommendation_metrics.get('coverage', 0),\n",
    "            'diversity': recommendation_metrics.get('category_diversity', 0),\n",
    "            'novelty': recommendation_metrics.get('novelty', 0)\n",
    "        }\n",
    "    \n",
    "    # Stocker dans l'historique\n",
    "    evaluation_history.append({\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'type': 'full_report',\n",
    "        'report': report\n",
    "    })\n",
    "    \n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfe8d9",
   "metadata": {},
   "source": [
    "<h1>Visualisation 2D des clusters</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "35ca75b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clusters(features_matrix, labels, save_path=\"clusters_visualization.png\"):\n",
    "    \"\"\"Visualisation 2D des clusters\"\"\"\n",
    "    try:\n",
    "        if features_matrix.shape[1] > 2:\n",
    "            # Réduction à 2D avec PCA\n",
    "            pca = PCA(n_components=2)\n",
    "            reduced_data = pca.fit_transform(features_matrix)\n",
    "        else:\n",
    "            reduced_data = features_matrix\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Scatter plot\n",
    "        unique_labels = np.unique(labels)\n",
    "        colors = plt.cm.Set3(np.linspace(0, 1, len(unique_labels)))\n",
    "        \n",
    "        for i, label in enumerate(unique_labels):\n",
    "            cluster_points = reduced_data[labels == label]\n",
    "            plt.scatter(cluster_points[:, 0], cluster_points[:, 1],\n",
    "                      color=colors[i], label=f'Cluster {label}', alpha=0.7)\n",
    "        \n",
    "        plt.title('Visualisation des Clusters K-Means')\n",
    "        plt.xlabel('Composante principale 1')\n",
    "        plt.ylabel('Composante principale 2')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        print(f\" Visualisation sauvegardée: {save_path}\")\n",
    "        \n",
    "        plt.close()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erreur visualisation: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f05dc13",
   "metadata": {},
   "source": [
    "<h1>Fonctions de Base de Données</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fb6402f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def get_connection():\n",
    "    \"\"\"Gestionnaire de connexion à la base de données\"\"\"\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = mysql.connector.connect(**DB_CONFIG)\n",
    "        yield connection\n",
    "    except Error as e:\n",
    "        print(f\" Erreur connexion MySQL: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if connection and connection.is_connected():\n",
    "            connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6266037",
   "metadata": {},
   "source": [
    "<h1>Charge les données depuis la base MySQL\"</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba24bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_db():\n",
    "    \"\"\"Charge les données depuis la base MySQL\"\"\"\n",
    "    global books_df, ratings_df, users_df, cart_df, data_quality_report\n",
    "    \n",
    "    try:\n",
    "        print(\"Chargement des données depuis MySQL...\")\n",
    "        \n",
    "        with get_connection() as conn:\n",
    "            cursor = conn.cursor(dictionary=True)\n",
    "            \n",
    "            # 1. Charger les livres\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT b.*, c.name as category_name \n",
    "                FROM books b \n",
    "                LEFT JOIN categories c ON b.category_id = c.id\n",
    "            \"\"\")\n",
    "            books = cursor.fetchall()\n",
    "            books_df = pd.DataFrame(books)\n",
    "            \n",
    "            # 2. Charger les évaluations\n",
    "            cursor.execute(\"SELECT user_id, book_id, rating FROM ratings\")\n",
    "            ratings = cursor.fetchall()\n",
    "            ratings_df = pd.DataFrame(ratings) if ratings else pd.DataFrame(columns=['user_id', 'book_id', 'rating'])\n",
    "            \n",
    "            # 3. Charger les utilisateurs\n",
    "            cursor.execute(\"SELECT id, username FROM users\")\n",
    "            users = cursor.fetchall()\n",
    "            users_df = pd.DataFrame(users) if users else pd.DataFrame(columns=['id', 'username'])\n",
    "            \n",
    "            # 4. Charger le panier\n",
    "            cursor.execute(\"SELECT user_id, book_id FROM cart\")\n",
    "            cart = cursor.fetchall()\n",
    "            cart_df = pd.DataFrame(cart) if cart else pd.DataFrame(columns=['user_id', 'book_id'])\n",
    "            \n",
    "            print(f\"Données brutes chargées: {len(books_df)} livres, {len(users_df)} utilisateurs, {len(ratings_df)} évaluations\")\n",
    "            \n",
    "            # Analyse de la qualité des données\n",
    "            data_quality_report = analyze_data_quality()\n",
    "            \n",
    "            # Prétraitement des données\n",
    "            if len(books_df) > 0:\n",
    "                books_df = clean_books_data(books_df)\n",
    "                extract_book_features()\n",
    "                train_kmeans_model()\n",
    "                prepare_user_profiles()\n",
    "            else:\n",
    "                print(\" Pas de livres dans la base de données\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\" Erreur chargement données: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8f70c7",
   "metadata": {},
   "source": [
    "<h1>Fonctions du Modèle K-Means</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "53b908d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kmeans_model(n_clusters=None):\n",
    "    \"\"\"Entraîne le modèle K-Means\"\"\"\n",
    "    global kmeans_model, book_clusters, book_features_matrix\n",
    "    \n",
    "    if book_features_matrix is None or len(book_features_matrix) < 2:\n",
    "        print(\" Pas assez de données pour K-Means\")\n",
    "        return False\n",
    "    \n",
    "    print(\" Entraînement du modèle K-Means...\")\n",
    "    \n",
    "    # Déterminer le nombre optimal de clusters\n",
    "    if n_clusters is None:\n",
    "        n_books = len(book_features_matrix)\n",
    "        n_clusters = min(max(5, n_books // 5), 15)\n",
    "    \n",
    "    print(f\" Utilisation de {n_clusters} clusters pour {len(book_features_matrix)} livres\")\n",
    "    \n",
    "    kmeans_model = KMeans(\n",
    "        n_clusters=n_clusters,\n",
    "        random_state=42,\n",
    "        n_init=10,\n",
    "        max_iter=300\n",
    "    )\n",
    "    \n",
    "    # Assigner les clusters\n",
    "    clusters = kmeans_model.fit_predict(book_features_matrix)\n",
    "    \n",
    "    # Stocker les clusters par livre\n",
    "    book_clusters = {}\n",
    "    for idx, cluster_id in enumerate(clusters):\n",
    "        book_id = index_to_book_id[idx]\n",
    "        book_clusters[book_id] = int(cluster_id)\n",
    "    \n",
    "    # Évaluer le clustering\n",
    "    clustering_metrics = evaluate_clustering(book_features_matrix, clusters)\n",
    "    \n",
    "    # Visualiser les clusters\n",
    "    visualize_clusters(book_features_matrix, clusters)\n",
    "    \n",
    "    # Afficher la distribution\n",
    "    cluster_counts = np.bincount(clusters)\n",
    "    print(f\" K-Means entraîné avec {n_clusters} clusters\")\n",
    "    print(f\" Métriques: Silhouette={clustering_metrics.get('silhouette_score', 0):.3f}\")\n",
    "    for i, count in enumerate(cluster_counts):\n",
    "        print(f\"   Cluster {i}: {count} livres\")\n",
    "    \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5809091f",
   "metadata": {},
   "source": [
    "<h1>Fonctions de Profil Utilisateur</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "edd460d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_user_profiles():\n",
    "    \"\"\"Prépare les profils utilisateurs depuis la base de données\"\"\"\n",
    "    global user_features\n",
    "    \n",
    "    print(\" Préparation des profils utilisateurs...\")\n",
    "    \n",
    "    try:\n",
    "        with get_connection() as conn:\n",
    "            cursor = conn.cursor(dictionary=True)\n",
    "            \n",
    "            # Récupérer tous les utilisateurs\n",
    "            cursor.execute(\"SELECT id FROM users\")\n",
    "            users = cursor.fetchall()\n",
    "            \n",
    "            for user in users:\n",
    "                user_id = user['id']\n",
    "                \n",
    "                # Récupérer les évaluations de l'utilisateur\n",
    "                cursor.execute(\"\"\"\n",
    "                    SELECT r.book_id, r.rating, b.category_id, b.author, b.price\n",
    "                    FROM ratings r\n",
    "                    JOIN books b ON r.book_id = b.id\n",
    "                    WHERE r.user_id = %s\n",
    "                \"\"\", (user_id,))\n",
    "                ratings = cursor.fetchall()\n",
    "                \n",
    "                if len(ratings) >= 1:\n",
    "                    ratings_df_local = pd.DataFrame(ratings)\n",
    "                    \n",
    "                    # Calcul des préférences\n",
    "                    avg_rating = ratings_df_local['rating'].mean()\n",
    "                    \n",
    "                    # Catégories préférées\n",
    "                    category_prefs = {}\n",
    "                    for _, row in ratings_df_local.iterrows():\n",
    "                        cat = row['category_id']\n",
    "                        rating_val = row['rating']\n",
    "                        category_prefs[cat] = category_prefs.get(cat, 0) + rating_val\n",
    "                    \n",
    "                    # Auteurs préférés\n",
    "                    author_prefs = {}\n",
    "                    for _, row in ratings_df_local.iterrows():\n",
    "                        author = row['author']\n",
    "                        rating_val = row['rating']\n",
    "                        author_prefs[author] = author_prefs.get(author, 0) + rating_val\n",
    "                    \n",
    "                    # Plage de prix préférée\n",
    "                    if not ratings_df_local.empty:\n",
    "                        avg_price = ratings_df_local['price'].mean()\n",
    "                        price_range = (max(0, avg_price * 0.5), avg_price * 1.5)\n",
    "                    else:\n",
    "                        price_range = (0, 100)\n",
    "                    \n",
    "                    user_features[user_id] = {\n",
    "                        'avg_rating': float(avg_rating),\n",
    "                        'category_prefs': dict(sorted(category_prefs.items(), key=lambda x: x[1], reverse=True)[:5]),\n",
    "                        'author_prefs': dict(sorted(author_prefs.items(), key=lambda x: x[1], reverse=True)[:10]),\n",
    "                        'preferred_price_range': price_range,\n",
    "                        'total_ratings': len(ratings),\n",
    "                        'last_updated': datetime.now().isoformat()\n",
    "                    }\n",
    "            \n",
    "            print(f\"Profils créés pour {len(user_features)} utilisateurs\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur préparation profils: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a75e2e",
   "metadata": {},
   "source": [
    "<h1>Recalcule le profil utilisateur</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a3418fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recalculate_user_profile(user_id):\n",
    "    \"\"\"Recalcule le profil utilisateur\"\"\"\n",
    "    global user_features\n",
    "    \n",
    "    try:\n",
    "        with get_connection() as conn:\n",
    "            cursor = conn.cursor(dictionary=True)\n",
    "            cursor.execute(\"\"\"\n",
    "                SELECT r.book_id, r.rating, b.category_id, b.author, b.price\n",
    "                FROM ratings r\n",
    "                JOIN books b ON r.book_id = b.id\n",
    "                WHERE r.user_id = %s\n",
    "            \"\"\", (user_id,))\n",
    "            ratings = cursor.fetchall()\n",
    "            \n",
    "            if ratings:\n",
    "                ratings_df_local = pd.DataFrame(ratings)\n",
    "                avg_rating = ratings_df_local['rating'].mean()\n",
    "                \n",
    "                category_prefs = {}\n",
    "                author_prefs = {}\n",
    "                \n",
    "                for _, row in ratings_df_local.iterrows():\n",
    "                    cat = row['category_id']\n",
    "                    rating_val = row['rating']\n",
    "                    category_prefs[cat] = category_prefs.get(cat, 0) + rating_val\n",
    "                    \n",
    "                    author = row['author']\n",
    "                    author_prefs[author] = author_prefs.get(author, 0) + rating_val\n",
    "                \n",
    "                good_ratings = ratings_df_local[ratings_df_local['rating'] >= 4]\n",
    "                if not good_ratings.empty:\n",
    "                    avg_price = good_ratings['price'].mean()\n",
    "                    price_range = (max(0, avg_price * 0.5), avg_price * 1.5)\n",
    "                else:\n",
    "                    price_range = (0, 100)\n",
    "                \n",
    "                user_features[user_id] = {\n",
    "                    'avg_rating': float(avg_rating),\n",
    "                    'category_prefs': dict(sorted(category_prefs.items(), key=lambda x: x[1], reverse=True)[:5]),\n",
    "                    'author_prefs': dict(sorted(author_prefs.items(), key=lambda x: x[1], reverse=True)[:10]),\n",
    "                    'preferred_price_range': price_range,\n",
    "                    'total_ratings': len(ratings),\n",
    "                    'last_updated': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "                print(f\"Profil {user_id} recalculé: {len(ratings)} évaluations\")\n",
    "            else:\n",
    "                # Profil par défaut\n",
    "                user_features[user_id] = {\n",
    "                    'avg_rating': 3.0,\n",
    "                    'category_prefs': {},\n",
    "                    'author_prefs': {},\n",
    "                    'preferred_price_range': (0, 100),\n",
    "                    'total_ratings': 0,\n",
    "                    'last_updated': datetime.now().isoformat()\n",
    "                }\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\" Erreur recalcul profil {user_id}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9547e391",
   "metadata": {},
   "source": [
    "<h1>Récupère le profil utilisateur</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "86fbe56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_profile(user_id):\n",
    "    \"\"\"Récupère le profil utilisateur\"\"\"\n",
    "    if user_id in user_features:\n",
    "        return user_features[user_id]\n",
    "    \n",
    "    recalculate_user_profile(user_id)\n",
    "    \n",
    "    if user_id in user_features:\n",
    "        return user_features[user_id]\n",
    "    \n",
    "    return {\n",
    "        'user_id': user_id,\n",
    "        'avg_rating': 3.0,\n",
    "        'category_prefs': {},\n",
    "        'author_prefs': {},\n",
    "        'preferred_price_range': (0, 100),\n",
    "        'total_ratings': 0,\n",
    "        'last_updated': datetime.now().isoformat()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbd0a43",
   "metadata": {},
   "source": [
    "<h1>Fonctions de Recommandation</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20b495ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(book_id, user_id=None, n_recommendations=8):\n",
    "    \"\"\"Recommandations pour un livre avec clustering K-Means\"\"\"\n",
    "    if not kmeans_model or book_id not in book_clusters:\n",
    "        print(f\" K-Means non entraîné ou livre {book_id} non trouvé\")\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Trouver le cluster du livre\n",
    "        book_cluster = book_clusters[book_id]\n",
    "        \n",
    "        # Trouver tous les livres du même cluster\n",
    "        cluster_book_ids = []\n",
    "        for bid, cid in book_clusters.items():\n",
    "            if cid == book_cluster and bid != book_id:\n",
    "                cluster_book_ids.append(bid)\n",
    "        \n",
    "        print(f\" Livre {book_id} dans le cluster {book_cluster} - {len(cluster_book_ids)} livres similaires\")\n",
    "        \n",
    "        # Si pas assez de livres dans le cluster, chercher dans les clusters similaires\n",
    "        if len(cluster_book_ids) < n_recommendations:\n",
    "            print(f\"Pas assez de livres dans le cluster {book_cluster}, recherche étendue...\")\n",
    "            \n",
    "            # Calculer la distance aux autres clusters\n",
    "            book_idx = book_id_to_index[book_id]\n",
    "            book_vector = book_features_matrix[book_idx].reshape(1, -1)\n",
    "            \n",
    "            # Trouver les distances aux centroïdes\n",
    "            distances = kmeans_model.transform(book_vector)[0]\n",
    "            \n",
    "            # Trier les clusters par distance\n",
    "            sorted_clusters = np.argsort(distances)\n",
    "            \n",
    "            # Prendre des livres des clusters les plus proches\n",
    "            additional_books = []\n",
    "            for cluster in sorted_clusters:\n",
    "                if cluster == book_cluster or len(additional_books) >= n_recommendations:\n",
    "                    continue\n",
    "                \n",
    "                # Trouver les livres de ce cluster\n",
    "                cluster_books = [bid for bid, cid in book_clusters.items() if cid == cluster and bid != book_id]\n",
    "                \n",
    "                # Prendre quelques livres de ce cluster\n",
    "                take_count = min(2, len(cluster_books))\n",
    "                if take_count > 0:\n",
    "                    import random\n",
    "                    selected = random.sample(cluster_books, take_count)\n",
    "                    additional_books.extend(selected)\n",
    "            \n",
    "            cluster_book_ids.extend(additional_books)\n",
    "        \n",
    "        # Limiter le nombre de livres\n",
    "        cluster_book_ids = cluster_book_ids[:n_recommendations * 3]\n",
    "        \n",
    "        recommendations = []\n",
    "        for rec_book_id in cluster_book_ids:\n",
    "            book_data = books_df[books_df['id'] == rec_book_id].iloc[0]\n",
    "            \n",
    "            # Calculer la similarité\n",
    "            same_cluster = book_clusters[rec_book_id] == book_cluster\n",
    "            similarity = 0.9 if same_cluster else 0.6\n",
    "            \n",
    "            personalization_score = 0\n",
    "            reason = f\"Cluster similaire ({book_cluster})\"\n",
    "            \n",
    "            if user_id and user_id in user_features:\n",
    "                profile = user_features[user_id]\n",
    "                \n",
    "                if book_data['category_id'] in profile['category_prefs']:\n",
    "                    personalization_score += profile['category_prefs'][book_data['category_id']] * 0.3\n",
    "                    reason = \"Catégorie préférée dans votre cluster\"\n",
    "                \n",
    "                if book_data['author'] in profile['author_prefs']:\n",
    "                    personalization_score += profile['author_prefs'][book_data['author']] * 0.5\n",
    "                    reason = \"Auteur que vous appréciez\"\n",
    "                \n",
    "                min_price, max_price = profile['preferred_price_range']\n",
    "                if min_price <= book_data['price'] <= max_price:\n",
    "                    personalization_score += 0.2\n",
    "            \n",
    "            final_score = similarity * 0.7 + personalization_score * 0.3\n",
    "            \n",
    "            recommendations.append({\n",
    "                'id': int(rec_book_id),\n",
    "                'title': str(book_data['title']),\n",
    "                'author': str(book_data['author']),\n",
    "                'category_id': int(book_data['category_id']),\n",
    "                'price': float(book_data['price']),\n",
    "                'image_url': str(book_data.get('image_url', f'https://via.placeholder.com/220x300?text={book_data[\"title\"]}')),\n",
    "                'similarity': similarity,\n",
    "                'personalization_score': personalization_score,\n",
    "                'final_score': final_score,\n",
    "                'cluster_id': int(book_clusters[rec_book_id]),\n",
    "                'reason': reason\n",
    "            })\n",
    "        \n",
    "        recommendations.sort(key=lambda x: x['final_score'], reverse=True)\n",
    "        return recommendations[:n_recommendations]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Erreur recommandations K-Means: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98a124",
   "metadata": {},
   "source": [
    "<h1>ecommandations intelligentes basées sur les préférences utilisateur</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ac3b6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intelligent_recommendations(user_id, n_recommendations=12):\n",
    "    \"\"\"Recommandations intelligentes basées sur les préférences utilisateur\"\"\"\n",
    "    try:\n",
    "        print(f\" Début recommandations intelligentes pour user {user_id}\")\n",
    "        \n",
    "        # Recharger les données à jour\n",
    "        load_data_from_db()\n",
    "        \n",
    "        if books_df is None or books_df.empty:\n",
    "            print(\" Pas de livres dans la base\")\n",
    "            return get_enhanced_fallback_recommendations()\n",
    "        \n",
    "        print(f\"{len(books_df)} livres disponibles dans {len(set(book_clusters.values()))} clusters\")\n",
    "        \n",
    "        # Recalculer le profil\n",
    "        recalculate_user_profile(user_id)\n",
    "        \n",
    "        # Récupérer le profil\n",
    "        profile = get_user_profile(user_id)\n",
    "        \n",
    "        total_ratings = profile.get('total_ratings', 0)\n",
    "        print(f\"Profil user {user_id}: {total_ratings} évaluations\")\n",
    "        \n",
    "        # Analyser les clusters préférés de l'utilisateur\n",
    "        user_cluster_prefs = {}\n",
    "        if total_ratings > 0 and ratings_df is not None:\n",
    "            user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
    "            for _, rating_row in user_ratings.iterrows():\n",
    "                book_id = rating_row['book_id']\n",
    "                if book_id in book_clusters:\n",
    "                    cluster_id = book_clusters[book_id]\n",
    "                    rating = rating_row['rating']\n",
    "                    user_cluster_prefs[cluster_id] = user_cluster_prefs.get(cluster_id, 0) + rating\n",
    "        \n",
    "        # Trouver les clusters préférés\n",
    "        preferred_clusters = []\n",
    "        if user_cluster_prefs:\n",
    "            sorted_clusters = sorted(user_cluster_prefs.items(), key=lambda x: x[1], reverse=True)\n",
    "            preferred_clusters = [cluster_id for cluster_id, _ in sorted_clusters[:3]]\n",
    "            print(f\" Clusters préférés: {preferred_clusters}\")\n",
    "        \n",
    "        # TOUJOURS inclure des livres\n",
    "        print(\" Stratégie: Inclure TOUS les livres (même évalués) avec scores ajustés\")\n",
    "        \n",
    "        recommended_books = []\n",
    "        books_processed = 0\n",
    "        \n",
    "        # Livres évalués par l'utilisateur\n",
    "        user_evaluated_books = set()\n",
    "        if ratings_df is not None and not ratings_df.empty:\n",
    "            user_ratings_data = ratings_df[ratings_df['user_id'] == user_id]\n",
    "            user_evaluated_books = set(user_ratings_data['book_id'].tolist())\n",
    "        \n",
    "        print(f\" Livres évalués par user {user_id}: {len(user_evaluated_books)}\")\n",
    "        \n",
    "        # Parcourir TOUS les livres\n",
    "        for _, book in books_df.iterrows():\n",
    "            books_processed += 1\n",
    "            score = 0\n",
    "            reasons = []\n",
    "            \n",
    "            # Vérifier si l'utilisateur a déjà évalué ce livre\n",
    "            is_evaluated = book['id'] in user_evaluated_books\n",
    "            \n",
    "            # Récupérer la note de l'utilisateur pour ce livre\n",
    "            user_rating = None\n",
    "            if is_evaluated and ratings_df is not None:\n",
    "                user_ratings = ratings_df[\n",
    "                    (ratings_df['user_id'] == user_id) & \n",
    "                    (ratings_df['book_id'] == book['id'])\n",
    "                ]\n",
    "                if not user_ratings.empty:\n",
    "                    user_rating = user_ratings.iloc[0]['rating']\n",
    "            \n",
    "            # Score de cluster (30%)\n",
    "            if book['id'] in book_clusters:\n",
    "                cluster_id = book_clusters[book['id']]\n",
    "                if cluster_id in preferred_clusters:\n",
    "                    cluster_score = user_cluster_prefs.get(cluster_id, 1) * 0.3\n",
    "                    score += cluster_score\n",
    "                    reasons.append(f\"Cluster préféré ({cluster_id})\")\n",
    "                else:\n",
    "                    score += 0.1 * 0.3\n",
    "            \n",
    "            # Score de catégorie (20%)\n",
    "            if 'category_prefs' in profile and book['category_id'] in profile['category_prefs']:\n",
    "                cat_score = profile['category_prefs'][book['category_id']]\n",
    "                if is_evaluated and user_rating:\n",
    "                    if user_rating >= 4:\n",
    "                        cat_score = cat_score * 1.2\n",
    "                        reasons.append(f\"Catégorie préférée (vous avez noté {user_rating}/5)\")\n",
    "                    elif user_rating <= 2:\n",
    "                        cat_score = cat_score * 0.3\n",
    "                    else:\n",
    "                        cat_score = cat_score * 0.7\n",
    "                else:\n",
    "                    reasons.append(\"Catégorie préférée\")\n",
    "                \n",
    "                score += cat_score * 0.2\n",
    "            \n",
    "            # Score d'auteur (20%)\n",
    "            if 'author_prefs' in profile and book['author'] in profile['author_prefs']:\n",
    "                author_score = profile['author_prefs'][book['author']]\n",
    "                if is_evaluated and user_rating:\n",
    "                    if user_rating >= 4:\n",
    "                        author_score = author_score * 1.3\n",
    "                        reasons.append(f\"Auteur apprécié (vous avez noté {user_rating}/5)\")\n",
    "                    elif user_rating <= 2:\n",
    "                        author_score = author_score * 0.2\n",
    "                    else:\n",
    "                        author_score = author_score * 0.6\n",
    "                else:\n",
    "                    reasons.append(\"Auteur apprécié\")\n",
    "                \n",
    "                score += author_score * 0.2\n",
    "            \n",
    "            # Score de prix (10%)\n",
    "            if 'preferred_price_range' in profile:\n",
    "                min_price, max_price = profile['preferred_price_range']\n",
    "                if min_price <= book['price'] <= max_price:\n",
    "                    score += 0.1\n",
    "                    reasons.append(\"Budget adapté\")\n",
    "            \n",
    "            # Score de popularité globale (10%)\n",
    "            if ratings_df is not None and not ratings_df.empty:\n",
    "                book_ratings = ratings_df[ratings_df['book_id'] == book['id']]\n",
    "                if not book_ratings.empty:\n",
    "                    avg_book_rating = book_ratings['rating'].mean()\n",
    "                    rating_count = len(book_ratings)\n",
    "                    popularity_score = avg_book_rating * np.log1p(rating_count + 1)\n",
    "                    score += popularity_score * 0.1\n",
    "                    if avg_book_rating >= 4.0:\n",
    "                        reasons.append(f\"Note: {avg_book_rating:.1f}/5\")\n",
    "            \n",
    "            # Score de nouveauté (10%)\n",
    "            novelty_score = 0.1 * (books_processed % 10) / 10\n",
    "            score += novelty_score\n",
    "            \n",
    "            # Score minimal pour TOUS les livres\n",
    "            base_score = 0.05\n",
    "            score += base_score\n",
    "            \n",
    "            # Récupérer les notes moyennes\n",
    "            avg_book_rating_val = 3.0\n",
    "            rating_count_val = 0\n",
    "            if ratings_df is not None and not ratings_df.empty:\n",
    "                book_ratings = ratings_df[ratings_df['book_id'] == book['id']]\n",
    "                if not book_ratings.empty:\n",
    "                    avg_book_rating_val = book_ratings['rating'].mean()\n",
    "                    rating_count_val = len(book_ratings)\n",
    "            \n",
    "            recommended_books.append({\n",
    "                'id': int(book['id']),\n",
    "                'title': str(book['title']),\n",
    "                'author': str(book['author']),\n",
    "                'score': float(score),\n",
    "                'reasons': reasons,\n",
    "                'category_id': int(book['category_id']),\n",
    "                'price': float(book['price']),\n",
    "                'image_url': book.get('image_url', f'https://via.placeholder.com/220x300?text={book[\"title\"]}'),\n",
    "                'is_evaluated': is_evaluated,\n",
    "                'user_rating': float(user_rating) if user_rating else None,\n",
    "                'avg_rating': float(avg_book_rating_val),\n",
    "                'rating_count': int(rating_count_val)\n",
    "            })\n",
    "        \n",
    "        print(f\"{len(recommended_books)} livres évalués pour recommandation\")\n",
    "        \n",
    "        # Trier par score\n",
    "        recommended_books.sort(key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        # Appliquer diversité intelligente\n",
    "        final_recommendations = []\n",
    "        categories_used = set()\n",
    "        authors_used = set()\n",
    "        clusters_used = set()\n",
    "        \n",
    "        # Mélanger livres évalués et non évalués\n",
    "        evaluated_included = 0\n",
    "        non_evaluated_included = 0\n",
    "        \n",
    "        for book in recommended_books:\n",
    "            if len(final_recommendations) >= n_recommendations:\n",
    "                break\n",
    "            \n",
    "            # Critères de diversité\n",
    "            category_ok = (len(categories_used) < 4 or book['category_id'] not in categories_used)\n",
    "            author_ok = (len(authors_used) < 6 or book['author'] not in authors_used)\n",
    "            \n",
    "            # Vérifier le cluster\n",
    "            cluster_id = book_clusters.get(book['id'])\n",
    "            cluster_ok = True\n",
    "            if cluster_id is not None:\n",
    "                cluster_books = [b for b in final_recommendations if book_clusters.get(b['id']) == cluster_id]\n",
    "                if len(cluster_books) >= 3:\n",
    "                    cluster_ok = False\n",
    "            \n",
    "            if (category_ok or author_ok) and cluster_ok:\n",
    "                # Générer une raison personnalisée\n",
    "                if book['is_evaluated']:\n",
    "                    if book['user_rating']:\n",
    "                        if book['user_rating'] >= 4:\n",
    "                            reason = f\" Vous avez adoré ({book['user_rating']}/5) - {format_reasons(book['reasons'])}\"\n",
    "                        elif book['user_rating'] <= 2:\n",
    "                            reason = f\"↩ Vous pourriez réévaluer ({book['user_rating']}/5)\"\n",
    "                        else:\n",
    "                            reason = f\" Déjà lu ({book['user_rating']}/5) - {format_reasons(book['reasons'])}\"\n",
    "                    else:\n",
    "                        reason = \"Déjà consulté - \" + format_reasons(book['reasons'])\n",
    "                    evaluated_included += 1\n",
    "                else:\n",
    "                    if book['avg_rating'] >= 4.5 and book['rating_count'] > 5:\n",
    "                        reason = f\" Excellent livre ({book['avg_rating']:.1f}/5) - \" + format_reasons(book['reasons'])\n",
    "                    elif book['avg_rating'] >= 4.0:\n",
    "                        reason = f\" Très bien noté ({book['avg_rating']:.1f}/5) - \" + format_reasons(book['reasons'])\n",
    "                    else:\n",
    "                        reason = \" Recommandation personnalisée - \" + format_reasons(book['reasons'])\n",
    "                    non_evaluated_included += 1\n",
    "                \n",
    "                final_recommendations.append({\n",
    "                    **book,\n",
    "                    'reason': reason or \"Recommandé pour vous\"\n",
    "                })\n",
    "                \n",
    "                categories_used.add(book['category_id'])\n",
    "                authors_used.add(book['author'])\n",
    "                if cluster_id is not None:\n",
    "                    clusters_used.add(cluster_id)\n",
    "        \n",
    "        # GARANTIE: Si moins de recommandations que demandé, prendre les meilleurs restants\n",
    "        if len(final_recommendations) < n_recommendations:\n",
    "            print(f\" Seulement {len(final_recommendations)} recommandations après diversité, ajout des meilleurs restants\")\n",
    "            for book in recommended_books:\n",
    "                if book['id'] not in [r['id'] for r in final_recommendations]:\n",
    "                    reason = book.get('reason', 'Suggestion basée sur nos collections')\n",
    "                    if not reason and book['is_evaluated'] and book['user_rating']:\n",
    "                        reason = f\"Vous avez noté {book['user_rating']}/5\"\n",
    "                    \n",
    "                    final_recommendations.append({\n",
    "                        **book,\n",
    "                        'reason': reason or \"Suggestion personnalisée\"\n",
    "                    })\n",
    "                \n",
    "                if len(final_recommendations) >= n_recommendations:\n",
    "                    break\n",
    "        \n",
    "        print(f\" {len(final_recommendations)} recommandations FINALES pour user {user_id} \"\n",
    "              f\"({evaluated_included} déjà évalués, {non_evaluated_included} nouveaux)\")\n",
    "        \n",
    "        return final_recommendations\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur recommandations intelligentes: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return get_enhanced_fallback_recommendations()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c747048",
   "metadata": {},
   "source": [
    "<h1>Fallback amélioré qui retourne TOUJOURS des livres</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0c9909e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_enhanced_fallback_recommendations():\n",
    "    \"\"\"Fallback amélioré qui retourne TOUJOURS des livres\"\"\"\n",
    "    try:\n",
    "        print(\"Utilisation du fallback amélioré\")\n",
    "        \n",
    "        if books_df is None or books_df.empty:\n",
    "            print(\"Base de données vide dans fallback\")\n",
    "            return []\n",
    "        \n",
    "        fallback_books = []\n",
    "        \n",
    "        for idx, book in books_df.iterrows():\n",
    "            if len(fallback_books) >= 12:\n",
    "                break\n",
    "            \n",
    "            # Calculer un score basique GARANTI\n",
    "            score = 0.5 + (idx % 10) * 0.05\n",
    "            \n",
    "            # Score de popularité\n",
    "            if ratings_df is not None and not ratings_df.empty:\n",
    "                book_ratings = ratings_df[ratings_df['book_id'] == book['id']]\n",
    "                if not book_ratings.empty:\n",
    "                    avg_rating = book_ratings['rating'].mean()\n",
    "                    rating_count = len(book_ratings)\n",
    "                    score += avg_rating * 0.2\n",
    "                    score += np.log1p(rating_count) * 0.1\n",
    "            \n",
    "            # Score minimal\n",
    "            if score < 0.3:\n",
    "                score = 0.3\n",
    "            \n",
    "            # Récupérer la note moyenne\n",
    "            avg_rating = 3.0\n",
    "            rating_count = 0\n",
    "            if ratings_df is not None and not ratings_df.empty:\n",
    "                book_ratings = ratings_df[ratings_df['book_id'] == book['id']]\n",
    "                if not book_ratings.empty:\n",
    "                    avg_rating = book_ratings['rating'].mean()\n",
    "                    rating_count = len(book_ratings)\n",
    "            \n",
    "            fallback_books.append({\n",
    "                'id': int(book['id']),\n",
    "                'title': str(book['title']),\n",
    "                'author': str(book['author']),\n",
    "                'category_id': int(book['category_id']),\n",
    "                'price': float(book['price']),\n",
    "                'image_url': book.get('image_url', f'https://via.placeholder.com/220x300?text={book[\"title\"]}'),\n",
    "                'score': float(score),\n",
    "                'avg_rating': float(avg_rating),\n",
    "                'rating_count': int(rating_count),\n",
    "                'reason': f\"Livre populaire ({avg_rating:.1f}/5)\" if rating_count > 0 else \"Découverte recommandée\"\n",
    "            })\n",
    "        \n",
    "        # GARANTIE: Toujours retourner au moins 12 livres\n",
    "        if len(fallback_books) < 12:\n",
    "            print(f\" Seulement {len(fallback_books)} livres, duplicata autorisé\")\n",
    "            while len(fallback_books) < 12 and len(fallback_books) > 0:\n",
    "                for book in fallback_books.copy():\n",
    "                    if len(fallback_books) >= 12:\n",
    "                        break\n",
    "                    new_book = book.copy()\n",
    "                    new_book['reason'] = \"Suggestion supplémentaire\"\n",
    "                    fallback_books.append(new_book)\n",
    "        \n",
    "        # Trier par score\n",
    "        fallback_books.sort(key=lambda x: x['score'], reverse=True)\n",
    "        \n",
    "        print(f\"{len(fallback_books)} livres dans fallback\")\n",
    "        return fallback_books[:12]\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur fallback: {e}\")\n",
    "        return [\n",
    "            {\n",
    "                'id': 999,\n",
    "                'title': 'Livre recommandé',\n",
    "                'author': 'Auteur',\n",
    "                'category_id': 1,\n",
    "                'price': 19.99,\n",
    "                'image_url': 'https://via.placeholder.com/220x300?text=Livre',\n",
    "                'reason': 'Recommandation système'\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4618ff62",
   "metadata": {},
   "source": [
    "<h1>Formate les raisons pour l'affichage</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "10867e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_reasons(reasons):\n",
    "    \"\"\"Formate les raisons pour l'affichage\"\"\"\n",
    "    if not reasons:\n",
    "        return \"Recommandé pour vous\"\n",
    "    \n",
    "    if len(reasons) > 2:\n",
    "        return f\"{reasons[0]}, {reasons[1]}\"\n",
    "    return \", \".join(reasons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094e4aa",
   "metadata": {},
   "source": [
    "<h1>Exécution et Test</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "235f6366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Démarrage du système de recommandation...\n",
      "Chargement des données depuis MySQL...\n",
      "Données brutes chargées: 503 livres, 6 utilisateurs, 39 évaluations\n",
      " Analyse de la qualité des données...\n",
      " Analyse qualité terminée: 0 problèmes détectés\n",
      " Nettoyage des données livres...\n",
      " Données nettoyées: 503 livres\n",
      " Extraction de features avancées...\n",
      " PCA appliqué: 8 composantes principales\n",
      "12 features extraites pour 503 livres\n",
      " Entraînement du modèle K-Means...\n",
      " Utilisation de 15 clusters pour 503 livres\n",
      " Évaluation du clustering K-Means...\n",
      " Évaluation terminée:\n",
      "   Silhouette: 0.242\n",
      "   Calinski-Harabasz: 129.1\n",
      "   Davies-Bouldin: 1.096\n",
      "   15 clusters, taille moyenne: 33.5\n",
      " Visualisation sauvegardée: clusters_visualization.png\n",
      " K-Means entraîné avec 15 clusters\n",
      " Métriques: Silhouette=0.242\n",
      "   Cluster 0: 72 livres\n",
      "   Cluster 1: 4 livres\n",
      "   Cluster 2: 48 livres\n",
      "   Cluster 3: 66 livres\n",
      "   Cluster 4: 2 livres\n",
      "   Cluster 5: 57 livres\n",
      "   Cluster 6: 69 livres\n",
      "   Cluster 7: 53 livres\n",
      "   Cluster 8: 3 livres\n",
      "   Cluster 9: 15 livres\n",
      "   Cluster 10: 5 livres\n",
      "   Cluster 11: 47 livres\n",
      "   Cluster 12: 8 livres\n",
      "   Cluster 13: 3 livres\n",
      "   Cluster 14: 51 livres\n",
      " Préparation des profils utilisateurs...\n",
      "Profils créés pour 6 utilisateurs\n",
      "\n",
      "==================================================\n",
      "ÉVALUATION AUTOMATIQUE AU DÉMARRAGE\n",
      "==================================================\n",
      " Évaluation du clustering K-Means...\n",
      " Évaluation terminée:\n",
      "   Silhouette: 0.242\n",
      "   Calinski-Harabasz: 129.1\n",
      "   Davies-Bouldin: 1.096\n",
      "   15 clusters, taille moyenne: 33.5\n",
      "\n",
      "Résumé clustering:\n",
      "   Score Silhouette: 0.242\n",
      "   Davies-Bouldin: 1.096\n",
      "   15 clusters\n",
      "\n",
      "Qualité des données:\n",
      "   Livres: 503\n",
      "   Évaluations: 39\n",
      "   Problèmes détectés: 0\n",
      "\n",
      "Système prêt pour les tests!\n"
     ]
    }
   ],
   "source": [
    "print(\"Démarrage du système de recommandation...\")\n",
    "\n",
    "# Charger les données\n",
    "load_data_from_db()\n",
    "\n",
    "# Exécuter une évaluation automatique au démarrage\n",
    "if book_clusters and book_features_matrix is not None:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ÉVALUATION AUTOMATIQUE AU DÉMARRAGE\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    clusters = []\n",
    "    valid_indices = []\n",
    "    for idx, book_id in index_to_book_id.items():\n",
    "        cluster_id = book_clusters.get(book_id, -1)\n",
    "        if cluster_id != -1:\n",
    "            clusters.append(cluster_id)\n",
    "            valid_indices.append(idx)\n",
    "    \n",
    "    if clusters:\n",
    "        clusters_array = np.array(clusters)\n",
    "        features_subset = book_features_matrix[valid_indices]\n",
    "        \n",
    "        if len(np.unique(clusters_array)) > 1:\n",
    "            metrics = evaluate_clustering(features_subset, clusters_array)\n",
    "            print(f\"\\nRésumé clustering:\")\n",
    "            print(f\"   Score Silhouette: {metrics.get('silhouette_score', 0):.3f}\")\n",
    "            print(f\"   Davies-Bouldin: {metrics.get('davies_bouldin', 0):.3f}\")\n",
    "            print(f\"   {metrics.get('n_clusters', 0)} clusters\")\n",
    "    \n",
    "    # Afficher le rapport de qualité\n",
    "    if data_quality_report:\n",
    "        print(f\"\\nQualité des données:\")\n",
    "        print(f\"   Livres: {data_quality_report.get('books', {}).get('total', 0)}\")\n",
    "        print(f\"   Évaluations: {data_quality_report.get('ratings', {}).get('total', 0)}\")\n",
    "        if 'issues' in data_quality_report:\n",
    "            print(f\"   Problèmes détectés: {len(data_quality_report['issues'])}\")\n",
    "            for issue in data_quality_report['issues']:\n",
    "                print(f\"     - {issue}\")\n",
    "\n",
    "print(\"\\nSystème prêt pour les tests!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56580b4d",
   "metadata": {},
   "source": [
    "<h1>Tests et Démonstrations</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dee00760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Profil utilisateur 1:\n",
      "   Nombre d'évaluations: 3\n",
      "   Note moyenne: 4.00\n",
      "   Catégories préférées: [3, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "user_id_test = 1\n",
    "profile = get_user_profile(user_id_test)\n",
    "print(f\"\\n Profil utilisateur {user_id_test}:\")\n",
    "print(f\"   Nombre d'évaluations: {profile.get('total_ratings', 0)}\")\n",
    "print(f\"   Note moyenne: {profile.get('avg_rating', 0):.2f}\")\n",
    "print(f\"   Catégories préférées: {list(profile.get('category_prefs', {}).keys())[:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2c1d6",
   "metadata": {},
   "source": [
    "<h2> Recommandations pour un livre (remplacez 1 par un ID livre existant)\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "673a2e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Livre 1 dans le cluster 8 - 2 livres similaires\n",
      "Pas assez de livres dans le cluster 8, recherche étendue...\n",
      "\n",
      "Recommandations pour le livre 1:\n",
      "   1. 1984 - Score: 1.650\n",
      "   2. Candide - Score: 1.410\n",
      "   3. Fondation - Score: 0.840\n",
      "   4. Les Misérables - Score: 0.750\n",
      "   5. Orgeuil Et Préjugés - Score: 0.750\n"
     ]
    }
   ],
   "source": [
    "book_id_test = 1\n",
    "recommendations = get_recommendations(book_id_test, user_id=user_id_test, n_recommendations=5)\n",
    "print(f\"\\nRecommandations pour le livre {book_id_test}:\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"   {i}. {rec['title']} - Score: {rec['final_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b4669f",
   "metadata": {},
   "source": [
    "<h1>Recommandations intelligentes pour utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2bfa03d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Début recommandations intelligentes pour user 1\n",
      "Chargement des données depuis MySQL...\n",
      "Données brutes chargées: 503 livres, 6 utilisateurs, 39 évaluations\n",
      " Analyse de la qualité des données...\n",
      " Analyse qualité terminée: 0 problèmes détectés\n",
      " Nettoyage des données livres...\n",
      " Données nettoyées: 503 livres\n",
      " Extraction de features avancées...\n",
      " PCA appliqué: 8 composantes principales\n",
      "12 features extraites pour 503 livres\n",
      " Entraînement du modèle K-Means...\n",
      " Utilisation de 15 clusters pour 503 livres\n",
      " Évaluation du clustering K-Means...\n",
      " Évaluation terminée:\n",
      "   Silhouette: 0.242\n",
      "   Calinski-Harabasz: 129.1\n",
      "   Davies-Bouldin: 1.096\n",
      "   15 clusters, taille moyenne: 33.5\n",
      " Visualisation sauvegardée: clusters_visualization.png\n",
      " K-Means entraîné avec 15 clusters\n",
      " Métriques: Silhouette=0.242\n",
      "   Cluster 0: 72 livres\n",
      "   Cluster 1: 4 livres\n",
      "   Cluster 2: 48 livres\n",
      "   Cluster 3: 66 livres\n",
      "   Cluster 4: 2 livres\n",
      "   Cluster 5: 57 livres\n",
      "   Cluster 6: 69 livres\n",
      "   Cluster 7: 53 livres\n",
      "   Cluster 8: 3 livres\n",
      "   Cluster 9: 15 livres\n",
      "   Cluster 10: 5 livres\n",
      "   Cluster 11: 47 livres\n",
      "   Cluster 12: 8 livres\n",
      "   Cluster 13: 3 livres\n",
      "   Cluster 14: 51 livres\n",
      " Préparation des profils utilisateurs...\n",
      "Profils créés pour 6 utilisateurs\n",
      "503 livres disponibles dans 15 clusters\n",
      "Profil 1 recalculé: 3 évaluations\n",
      "Profil user 1: 3 évaluations\n",
      " Clusters préférés: [8]\n",
      " Stratégie: Inclure TOUS les livres (même évalués) avec scores ajustés\n",
      " Livres évalués par user 1: 3\n",
      "503 livres évalués pour recommandation\n",
      " 8 recommandations FINALES pour user 1 (3 déjà évalués, 5 nouveaux)\n",
      "\n",
      "Recommandations intelligentes pour utilisateur 1:\n",
      "   1. 1984 - Score: 6.471\n",
      "      Raison:  Vous avez adoré (4.0/5) - Cluster préféré (8), Catégorie préférée (vous avez noté 4/5)\n",
      "   2. Le Petit Prince - Score: 5.587\n",
      "      Raison:  Vous avez adoré (5.0/5) - Cluster préféré (8), Catégorie préférée (vous avez noté 5/5)\n",
      "   3. Candide - Score: 5.277\n",
      "      Raison:  Déjà lu (3.0/5) - Cluster préféré (8), Budget adapté\n",
      "   4. Animal Farm - Score: 2.040\n",
      "      Raison:  Recommandation personnalisée - Catégorie préférée, Auteur apprécié\n",
      "   5. Harry Potter À L'École Des Sorciers - Score: 1.953\n",
      "      Raison:  Très bien noté (5.0/5) - Catégorie préférée, Budget adapté\n",
      "   6. Les Misérables - Score: 1.581\n",
      "      Raison:  Très bien noté (4.2/5) - Catégorie préférée, Budget adapté\n",
      "   7. Orgeuil Et Préjugés - Score: 1.454\n",
      "      Raison:  Très bien noté (4.5/5) - Catégorie préférée, Budget adapté\n",
      "   8. Le Comte De Monte-Cristo - Score: 1.409\n",
      "      Raison:  Très bien noté (5.0/5) - Catégorie préférée, Budget adapté\n"
     ]
    }
   ],
   "source": [
    "intelligent_recs = get_intelligent_recommendations(user_id_test, n_recommendations=8)\n",
    "print(f\"\\nRecommandations intelligentes pour utilisateur {user_id_test}:\")\n",
    "for i, rec in enumerate(intelligent_recs, 1):\n",
    "    print(f\"   {i}. {rec['title']} - Score: {rec['score']:.3f}\")\n",
    "    print(f\"      Raison: {rec['reason']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f0763",
   "metadata": {},
   "source": [
    "<h1> Évaluation complète pour un utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c2208f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ÉVALUATION COMPLÈTE POUR UTILISATEUR 1\n",
      "============================================================\n",
      " Évaluation du clustering K-Means...\n",
      " Évaluation terminée:\n",
      "   Silhouette: 0.242\n",
      "   Calinski-Harabasz: 129.1\n",
      "   Davies-Bouldin: 1.096\n",
      "   15 clusters, taille moyenne: 33.5\n",
      " Début recommandations intelligentes pour user 1\n",
      "Chargement des données depuis MySQL...\n",
      "Données brutes chargées: 503 livres, 6 utilisateurs, 39 évaluations\n",
      " Analyse de la qualité des données...\n",
      " Analyse qualité terminée: 0 problèmes détectés\n",
      " Nettoyage des données livres...\n",
      " Données nettoyées: 503 livres\n",
      " Extraction de features avancées...\n",
      " PCA appliqué: 8 composantes principales\n",
      "12 features extraites pour 503 livres\n",
      " Entraînement du modèle K-Means...\n",
      " Utilisation de 15 clusters pour 503 livres\n",
      " Évaluation du clustering K-Means...\n",
      " Évaluation terminée:\n",
      "   Silhouette: 0.242\n",
      "   Calinski-Harabasz: 129.1\n",
      "   Davies-Bouldin: 1.096\n",
      "   15 clusters, taille moyenne: 33.5\n",
      " Visualisation sauvegardée: clusters_visualization.png\n",
      " K-Means entraîné avec 15 clusters\n",
      " Métriques: Silhouette=0.242\n",
      "   Cluster 0: 72 livres\n",
      "   Cluster 1: 4 livres\n",
      "   Cluster 2: 48 livres\n",
      "   Cluster 3: 66 livres\n",
      "   Cluster 4: 2 livres\n",
      "   Cluster 5: 57 livres\n",
      "   Cluster 6: 69 livres\n",
      "   Cluster 7: 53 livres\n",
      "   Cluster 8: 3 livres\n",
      "   Cluster 9: 15 livres\n",
      "   Cluster 10: 5 livres\n",
      "   Cluster 11: 47 livres\n",
      "   Cluster 12: 8 livres\n",
      "   Cluster 13: 3 livres\n",
      "   Cluster 14: 51 livres\n",
      " Préparation des profils utilisateurs...\n",
      "Profils créés pour 6 utilisateurs\n",
      "503 livres disponibles dans 15 clusters\n",
      "Profil 1 recalculé: 3 évaluations\n",
      "Profil user 1: 3 évaluations\n",
      " Clusters préférés: [8]\n",
      " Stratégie: Inclure TOUS les livres (même évalués) avec scores ajustés\n",
      " Livres évalués par user 1: 3\n",
      "503 livres évalués pour recommandation\n",
      " 12 recommandations FINALES pour user 1 (3 déjà évalués, 9 nouveaux)\n",
      "Évaluation des recommandations...\n",
      "Génération du rapport d'évaluation...\n",
      "\n",
      "RÉSULTATS:\n",
      "   - Score Silhouette: 0.242\n",
      "   - Couverture recommandations: 2.4%\n",
      "   - Diversité catégories: 25.0%\n",
      "   - Nouveauté: 75.0%\n",
      "\n",
      " NOTEBOOK TERMINÉ AVEC SUCCÈS!\n",
      "Vous pouvez maintenant exécuter différentes cellules pour tester le système.\n"
     ]
    }
   ],
   "source": [
    "def run_full_evaluation(user_id):\n",
    "    \"\"\"Exécute une évaluation complète pour un utilisateur\"\"\"\n",
    "    print(f\"\\n ÉVALUATION COMPLÈTE POUR UTILISATEUR {user_id}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Évaluer le clustering\n",
    "    clustering_metrics = None\n",
    "    if book_features_matrix is not None and book_clusters:\n",
    "        clusters = []\n",
    "        valid_indices = []\n",
    "        for idx, book_id in index_to_book_id.items():\n",
    "            cluster_id = book_clusters.get(book_id, -1)\n",
    "            if cluster_id != -1:\n",
    "                clusters.append(cluster_id)\n",
    "                valid_indices.append(idx)\n",
    "        \n",
    "        if clusters:\n",
    "            clusters_array = np.array(clusters)\n",
    "            features_subset = book_features_matrix[valid_indices]\n",
    "            clustering_metrics = evaluate_clustering(features_subset, clusters_array)\n",
    "    \n",
    "    # 2. Générer et évaluer les recommandations\n",
    "    recommendations = get_intelligent_recommendations(user_id)\n",
    "    \n",
    "    # Récupérer l'historique\n",
    "    user_history = {'evaluated_books': []}\n",
    "    if ratings_df is not None:\n",
    "        user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
    "        user_history['evaluated_books'] = user_ratings['book_id'].tolist()\n",
    "    \n",
    "    rec_metrics = evaluate_recommendations(\n",
    "        recommendations,\n",
    "        user_history=user_history,\n",
    "        all_books=books_df['id'].tolist() if books_df is not None else []\n",
    "    )\n",
    "    \n",
    "    # 3. Générer un rapport\n",
    "    report = generate_evaluation_report(\n",
    "        clustering_metrics=clustering_metrics,\n",
    "        recommendation_metrics=rec_metrics\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nRÉSULTATS:\")\n",
    "    if clustering_metrics:\n",
    "        print(f\"   - Score Silhouette: {clustering_metrics.get('silhouette_score', 0):.3f}\")\n",
    "    print(f\"   - Couverture recommandations: {rec_metrics.get('coverage', 0):.1%}\")\n",
    "    print(f\"   - Diversité catégories: {rec_metrics.get('category_diversity', 0):.1%}\")\n",
    "    print(f\"   - Nouveauté: {rec_metrics.get('novelty', 0):.1%}\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Exécuter l'évaluation\n",
    "evaluation_report = run_full_evaluation(user_id_test)\n",
    "\n",
    "# %%\n",
    "print(\"\\n NOTEBOOK TERMINÉ AVEC SUCCÈS!\")\n",
    "print(\"Vous pouvez maintenant exécuter différentes cellules pour tester le système.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfd644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5002\n",
      " * Running on http://100.90.113.220:5002\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "# %%\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return \"API de Recommandation avec MySQL, K-Means et Évaluation 🚀\"\n",
    "\n",
    "# %%\n",
    "@app.route('/health')\n",
    "def health():\n",
    "    return jsonify({\n",
    "        'status': 'healthy',\n",
    "        'books': len(books_df) if books_df is not None else 0,\n",
    "        'users_with_profiles': len(user_features),\n",
    "        'clusters': len(set(book_clusters.values())) if book_clusters else 0,\n",
    "        'model': 'K-Means',\n",
    "        'evaluation_ready': len(evaluation_history) > 0\n",
    "    })\n",
    "\n",
    "# %%\n",
    "@app.route('/initialize', methods=['POST'])\n",
    "def initialize():\n",
    "    \"\"\"Initialise le modèle\"\"\"\n",
    "    try:\n",
    "        load_data_from_db()\n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'message': f'Modèle initialisé avec {len(books_df)} livres et {len(user_features)} profils',\n",
    "            'clusters': len(set(book_clusters.values())) if book_clusters else 0,\n",
    "            'data_quality_issues': len(data_quality_report.get('issues', []))\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/recommend/<int:book_id>', methods=['GET'])\n",
    "def recommend(book_id):\n",
    "    \"\"\"Recommandations pour un livre\"\"\"\n",
    "    try:\n",
    "        user_id = request.args.get('user_id', type=int)\n",
    "        \n",
    "        recommendations = get_recommendations(\n",
    "            book_id, \n",
    "            user_id=user_id,\n",
    "            n_recommendations=8\n",
    "        )\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'recommendations': recommendations,\n",
    "            'count': len(recommendations),\n",
    "            'model': 'K-Means'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur route /recommend: {e}\")\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/intelligent-recommendations/<int:user_id>', methods=['GET'])\n",
    "def intelligent_recommendations(user_id):\n",
    "    \"\"\"Recommandations intelligentes basées sur les préférences\"\"\"\n",
    "    try:\n",
    "        print(f\"Début recommandations intelligentes pour user {user_id}\")\n",
    "        \n",
    "        # Forcer le chargement des données\n",
    "        load_data_from_db()\n",
    "        \n",
    "        if books_df is None or books_df.empty:\n",
    "            print(\"Pas de livres dans la base\")\n",
    "            return jsonify({\n",
    "                'status': 'success',\n",
    "                'recommendations': [],\n",
    "                'count': 0,\n",
    "                'message': 'Base de données vide'\n",
    "            })\n",
    "        \n",
    "        print(f\"{len(books_df)} livres disponibles\")\n",
    "        \n",
    "        # Obtenir les recommandations\n",
    "        recommendations = get_intelligent_recommendations(user_id)\n",
    "        \n",
    "        print(f\" {len(recommendations)} recommandations générées\")\n",
    "        \n",
    "        # Formater la réponse\n",
    "        formatted_recommendations = []\n",
    "        for rec in recommendations:\n",
    "            formatted_rec = {\n",
    "                'id': rec['id'],\n",
    "                'title': rec['title'],\n",
    "                'author': rec['author'],\n",
    "                'reason': rec.get('reason', 'Recommandé pour vous'),\n",
    "                'category_id': rec.get('category_id', 0),\n",
    "                'price': rec.get('price', 0),\n",
    "                'image_url': rec.get('image_url', f'https://via.placeholder.com/220x300?text={rec[\"title\"]}'),\n",
    "                'score': rec.get('score', 0.5)\n",
    "            }\n",
    "            formatted_recommendations.append(formatted_rec)\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'recommendations': formatted_recommendations,\n",
    "            'count': len(formatted_recommendations),\n",
    "            'algorithm': 'intelligent',\n",
    "            'model': 'K-Means',\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'books_in_db': len(books_df)\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur route recommandations intelligentes: {e}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        # Fallback\n",
    "        fallback_recs = get_enhanced_fallback_recommendations()\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'recommendations': fallback_recs,\n",
    "            'count': len(fallback_recs),\n",
    "            'algorithm': 'fallback',\n",
    "            'timestamp': datetime.now().isoformat()\n",
    "        })\n",
    "\n",
    "# %%\n",
    "@app.route('/data-quality', methods=['GET'])\n",
    "def get_data_quality():\n",
    "    \"\"\"Retourne le rapport de qualité des données\"\"\"\n",
    "    try:\n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'quality_report': data_quality_report\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/evaluate/clustering', methods=['GET'])\n",
    "def evaluate_clustering_route():\n",
    "    \"\"\"Évalue le clustering\"\"\"\n",
    "    try:\n",
    "        if book_features_matrix is None or not book_clusters:\n",
    "            return jsonify({'status': 'error', 'message': 'Clustering non disponible'}), 400\n",
    "        \n",
    "        # Préparer les données\n",
    "        clusters = []\n",
    "        valid_indices = []\n",
    "        \n",
    "        for idx, book_id in index_to_book_id.items():\n",
    "            cluster_id = book_clusters.get(book_id, -1)\n",
    "            if cluster_id != -1:\n",
    "                clusters.append(cluster_id)\n",
    "                valid_indices.append(idx)\n",
    "        \n",
    "        if not clusters:\n",
    "            return jsonify({'status': 'error', 'message': 'Aucun cluster valide'}), 400\n",
    "        \n",
    "        clusters_array = np.array(clusters)\n",
    "        features_subset = book_features_matrix[valid_indices]\n",
    "        \n",
    "        # Évaluer\n",
    "        metrics = evaluate_clustering(features_subset, clusters_array)\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'metrics': metrics,\n",
    "            'model': 'K-Means'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/evaluate/recommendations/<int:user_id>', methods=['GET'])\n",
    "def evaluate_user_recommendations(user_id):\n",
    "    \"\"\"Évalue les recommandations pour un utilisateur\"\"\"\n",
    "    try:\n",
    "        n_recommendations = request.args.get('n', default=10, type=int)\n",
    "        \n",
    "        # Générer les recommandations\n",
    "        recommendations = get_intelligent_recommendations(user_id, n_recommendations)\n",
    "        \n",
    "        # Récupérer l'historique\n",
    "        user_history = {'evaluated_books': []}\n",
    "        if ratings_df is not None:\n",
    "            user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
    "            user_history['evaluated_books'] = user_ratings['book_id'].tolist()\n",
    "        \n",
    "        # Évaluer\n",
    "        rec_metrics = evaluate_recommendations(\n",
    "            recommendations,\n",
    "            user_history=user_history,\n",
    "            all_books=books_df['id'].tolist() if books_df is not None else []\n",
    "        )\n",
    "        \n",
    "        # Générer un rapport\n",
    "        report = generate_evaluation_report(\n",
    "            clustering_metrics=None,\n",
    "            recommendation_metrics=rec_metrics\n",
    "        )\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'evaluation': {\n",
    "                'recommendations': rec_metrics,\n",
    "                'report': report\n",
    "            },\n",
    "            'user_id': user_id\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/debug/full/<int:user_id>', methods=['GET'])\n",
    "def debug_full(user_id):\n",
    "    \"\"\"Debug complet avec évaluation\"\"\"\n",
    "    try:\n",
    "        # 1. Recharger les données\n",
    "        load_data_from_db()\n",
    "        \n",
    "        # 2. Évaluer le clustering\n",
    "        clustering_metrics = None\n",
    "        if book_features_matrix is not None and book_clusters:\n",
    "            clusters = []\n",
    "            valid_indices = []\n",
    "            for idx, book_id in index_to_book_id.items():\n",
    "                cluster_id = book_clusters.get(book_id, -1)\n",
    "                if cluster_id != -1:\n",
    "                    clusters.append(cluster_id)\n",
    "                    valid_indices.append(idx)\n",
    "            \n",
    "            if clusters:\n",
    "                clusters_array = np.array(clusters)\n",
    "                features_subset = book_features_matrix[valid_indices]\n",
    "                clustering_metrics = evaluate_clustering(features_subset, clusters_array)\n",
    "        \n",
    "        # 3. Générer des recommandations\n",
    "        recommendations = get_intelligent_recommendations(user_id)\n",
    "        \n",
    "        # 4. Évaluer les recommandations\n",
    "        user_history = {'evaluated_books': []}\n",
    "        if ratings_df is not None:\n",
    "            user_ratings = ratings_df[ratings_df['user_id'] == user_id]\n",
    "            user_history['evaluated_books'] = user_ratings['book_id'].tolist()\n",
    "        \n",
    "        rec_metrics = evaluate_recommendations(\n",
    "            recommendations,\n",
    "            user_history=user_history,\n",
    "            all_books=books_df['id'].tolist() if books_df is not None else []\n",
    "        )\n",
    "        \n",
    "        # 5. Rapport complet\n",
    "        report = generate_evaluation_report(\n",
    "            clustering_metrics=clustering_metrics,\n",
    "            recommendation_metrics=rec_metrics\n",
    "        )\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'user_id': user_id,\n",
    "            'clustering_evaluation': clustering_metrics,\n",
    "            'recommendation_evaluation': rec_metrics,\n",
    "            'full_report': report,\n",
    "            'data_quality': data_quality_report,\n",
    "            'n_recommendations': len(recommendations)\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/user-profile/<int:user_id>', methods=['GET'])\n",
    "def user_profile(user_id):\n",
    "    \"\"\"Récupère le profil utilisateur\"\"\"\n",
    "    try:\n",
    "        profile = get_user_profile(user_id)\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'profile': {\n",
    "                'user_id': user_id,\n",
    "                'avg_rating': profile['avg_rating'],\n",
    "                'total_ratings': profile['total_ratings'],\n",
    "                'preferred_categories': list(profile['category_prefs'].keys())[:3],\n",
    "                'preferred_authors': list(profile['author_prefs'].keys())[:5],\n",
    "                'price_range': profile['preferred_price_range'],\n",
    "                'last_updated': profile['last_updated']\n",
    "            }\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur route /user-profile: {e}\")\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/refresh-profile/<int:user_id>', methods=['POST'])\n",
    "def refresh_profile(user_id):\n",
    "    \"\"\"Force le rafraîchissement du profil\"\"\"\n",
    "    try:\n",
    "        recalculate_user_profile(user_id)\n",
    "        \n",
    "        if user_id in user_features:\n",
    "            return jsonify({\n",
    "                'status': 'success',\n",
    "                'message': f'Profil {user_id} rafraîchi',\n",
    "                'profile': get_user_profile(user_id)\n",
    "            })\n",
    "        else:\n",
    "            return jsonify({'status': 'error', 'message': 'Erreur rafraîchissement'}), 500\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" Erreur route /refresh-profile: {e}\")\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/clusters/visualization', methods=['GET'])\n",
    "def get_clusters_visualization():\n",
    "    \"\"\"Retourne la visualisation des clusters\"\"\"\n",
    "    try:\n",
    "        if book_features_matrix is None or not book_clusters:\n",
    "            return jsonify({'status': 'error', 'message': 'Clustering non disponible'}), 400\n",
    "        \n",
    "        # Préparer les données pour la visualisation\n",
    "        clusters = []\n",
    "        valid_indices = []\n",
    "        for idx, book_id in index_to_book_id.items():\n",
    "            cluster_id = book_clusters.get(book_id, -1)\n",
    "            if cluster_id != -1:\n",
    "                clusters.append(cluster_id)\n",
    "                valid_indices.append(idx)\n",
    "        \n",
    "        if not clusters:\n",
    "            return jsonify({'status': 'error', 'message': 'Aucun cluster valide'}), 400\n",
    "        \n",
    "        clusters_array = np.array(clusters)\n",
    "        features_subset = book_features_matrix[valid_indices]\n",
    "        \n",
    "        # Créer la visualisation\n",
    "        save_path = \"static/clusters_visualization.png\"\n",
    "        success = visualize_clusters(features_subset, clusters_array, save_path)\n",
    "        \n",
    "        if success:\n",
    "            return jsonify({\n",
    "                'status': 'success',\n",
    "                'visualization_url': f'/{save_path}',\n",
    "                'message': 'Visualisation créée avec succès'\n",
    "            })\n",
    "        else:\n",
    "            return jsonify({'status': 'error', 'message': 'Erreur création visualisation'}), 500\n",
    "            \n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
    "\n",
    "# %%\n",
    "@app.route('/recommendations/fallback', methods=['GET'])\n",
    "def get_fallback_recommendations():\n",
    "    \"\"\"Retourne des recommandations fallback\"\"\"\n",
    "    try:\n",
    "        recommendations = get_enhanced_fallback_recommendations()\n",
    "        \n",
    "        return jsonify({\n",
    "            'status': 'success',\n",
    "            'recommendations': recommendations,\n",
    "            'count': len(recommendations),\n",
    "            'algorithm': 'fallback'\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({'status': 'error', 'message': str(e)}), 500   \n",
    "app.run(host='0.0.0.0', port=5002, debug=True, use_reloader=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
